{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Wave_write.__del__ at 0x00000211C14F90D8>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Abhijeet\\Anaconda3\\lib\\wave.py\", line 327, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\Abhijeet\\Anaconda3\\lib\\wave.py\", line 445, in close\n",
      "    self._ensure_header_written(0)\n",
      "  File \"C:\\Users\\Abhijeet\\Anaconda3\\lib\\wave.py\", line 463, in _ensure_header_written\n",
      "    raise Error('# channels not specified')\n",
      "wave.Error: # channels not specified\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "ba6c451b8e6ba07de187ee7c79f0a6e9319a594e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Respiratory_Sound_Database']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the folder\n",
    "os.listdir('respiratory_sound_database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#loading the demographic_info.txt converting into csv\n",
    "df_no_diagnosis = pd.read_csv('demographic_info.txt', names = \n",
    "                 ['Patient number', 'Age', 'Sex' , 'Adult BMI (kg/m2)', 'Child Weight (kg)' , 'Child Height (cm)'],\n",
    "                 delimiter = ' ')\n",
    "\n",
    "diagnosis = pd.read_csv('respiratory_sound_database/Respiratory_Sound_Database/patient_diagnosis.csv', names = ['Patient number', 'Diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient number</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Adult BMI (kg/m2)</th>\n",
       "      <th>Child Weight (kg)</th>\n",
       "      <th>Child Height (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>3.00</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>0.75</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.8</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>70.00</td>\n",
       "      <td>F</td>\n",
       "      <td>33.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>70.00</td>\n",
       "      <td>F</td>\n",
       "      <td>28.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>7.00</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient number    Age Sex  Adult BMI (kg/m2)  Child Weight (kg)  \\\n",
       "0             101   3.00   F                NaN               19.0   \n",
       "1             102   0.75   F                NaN                9.8   \n",
       "2             103  70.00   F              33.00                NaN   \n",
       "3             104  70.00   F              28.47                NaN   \n",
       "4             105   7.00   F                NaN               32.0   \n",
       "\n",
       "   Child Height (cm)  \n",
       "0               99.0  \n",
       "1               73.0  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4              135.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_diagnosis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_diagnosis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient number</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>URTI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Asthma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>COPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>URTI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient number Diagnosis\n",
       "0             101      URTI\n",
       "1             102   Healthy\n",
       "2             103    Asthma\n",
       "3             104      COPD\n",
       "4             105      URTI"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "912a707b2fcf4ab2711b19bfa4341c5b58d9dcc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COPD              64\n",
       "Healthy           26\n",
       "URTI              14\n",
       "Bronchiectasis     7\n",
       "Bronchiolitis      6\n",
       "Pneumonia          6\n",
       "LRTI               2\n",
       "Asthma             1\n",
       "Name: Diagnosis, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joining the two csv by patient number as index\n",
    "\n",
    "df =  df_no_diagnosis.join(diagnosis.set_index('Patient number'), on = 'Patient number', how = 'left')\n",
    "#listing the number of total unique diseases\n",
    "df['Diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient number</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Adult BMI (kg/m2)</th>\n",
       "      <th>Child Weight (kg)</th>\n",
       "      <th>Child Height (cm)</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>3.00</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>URTI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>0.75</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.8</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>70.00</td>\n",
       "      <td>F</td>\n",
       "      <td>33.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asthma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>70.00</td>\n",
       "      <td>F</td>\n",
       "      <td>28.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>7.00</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>URTI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient number    Age Sex  Adult BMI (kg/m2)  Child Weight (kg)  \\\n",
       "0             101   3.00   F                NaN               19.0   \n",
       "1             102   0.75   F                NaN                9.8   \n",
       "2             103  70.00   F              33.00                NaN   \n",
       "3             104  70.00   F              28.47                NaN   \n",
       "4             105   7.00   F                NaN               32.0   \n",
       "\n",
       "   Child Height (cm) Diagnosis  \n",
       "0               99.0      URTI  \n",
       "1               73.0   Healthy  \n",
       "2                NaN    Asthma  \n",
       "3                NaN      COPD  \n",
       "4              135.0      URTI  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "3e1d7ddaac465d3af5b8594b86ea6033e1048b08"
   },
   "outputs": [],
   "source": [
    "#loading the names of audio files and creating a file on that called filenames\n",
    "#root = 'respiratory_sound_database/Respiratory_Sound_Database/audio_and_txt_files/'\n",
    "root = 'real/sample/'\n",
    "filenames = [s.split('.')[0] for s in os.listdir(path = root) if '.txt' in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['101_1b1_Pr_sc_Meditron',\n",
       " '102_1b1_Ar_sc_Meditron',\n",
       " '103_2b2_Ar_mc_LittC2SE',\n",
       " '104_1b1_Al_sc_Litt3200',\n",
       " '104_1b1_Ar_sc_Litt3200',\n",
       " '104_1b1_Ll_sc_Litt3200',\n",
       " '104_1b1_Lr_sc_Litt3200',\n",
       " '104_1b1_Pl_sc_Litt3200',\n",
       " '104_1b1_Pr_sc_Litt3200',\n",
       " '105_1b1_Tc_sc_Meditron',\n",
       " '106_2b1_Pl_mc_LittC2SE',\n",
       " '106_2b1_Pr_mc_LittC2SE',\n",
       " '107_2b3_Al_mc_AKGC417L',\n",
       " '107_2b3_Ar_mc_AKGC417L',\n",
       " '107_2b3_Ll_mc_AKGC417L',\n",
       " '107_2b3_Lr_mc_AKGC417L']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "06d7a65e5eb860b69d08e3978fc89bd5a97056e7"
   },
   "outputs": [],
   "source": [
    "#function to extract annotation data of each file and data from the name of every file and join them to form a single csv\n",
    "def Extract_Annotation_Data(file_name, root):\n",
    "    tokens = file_name.split('_') #split the file name at '-'\n",
    "    recording_info = pd.DataFrame(data = [tokens], columns = ['Patient number', 'Recording index', 'Chest location','Acquisition mode','Recording equipment']) #load the information from file name\n",
    "    recording_annotations = pd.read_csv(os.path.join(root, file_name + '.txt'), names = ['Start', 'End', 'Crackles', 'Wheezes'], delimiter= '\\t') #load the information from annotation\n",
    "    return (recording_info, recording_annotations) #return both the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "91a9bc4000bb65013bcc035a0b9d9564651ebd33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient number</th>\n",
       "      <th>Recording index</th>\n",
       "      <th>Chest location</th>\n",
       "      <th>Acquisition mode</th>\n",
       "      <th>Recording equipment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>1b1</td>\n",
       "      <td>Pr</td>\n",
       "      <td>sc</td>\n",
       "      <td>Meditron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>1b1</td>\n",
       "      <td>Ar</td>\n",
       "      <td>sc</td>\n",
       "      <td>Meditron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103</td>\n",
       "      <td>2b2</td>\n",
       "      <td>Ar</td>\n",
       "      <td>mc</td>\n",
       "      <td>LittC2SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104</td>\n",
       "      <td>1b1</td>\n",
       "      <td>Al</td>\n",
       "      <td>sc</td>\n",
       "      <td>Litt3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104</td>\n",
       "      <td>1b1</td>\n",
       "      <td>Ar</td>\n",
       "      <td>sc</td>\n",
       "      <td>Litt3200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patient number Recording index Chest location Acquisition mode  \\\n",
       "0            101             1b1             Pr               sc   \n",
       "0            102             1b1             Ar               sc   \n",
       "0            103             2b2             Ar               mc   \n",
       "0            104             1b1             Al               sc   \n",
       "0            104             1b1             Ar               sc   \n",
       "\n",
       "  Recording equipment  \n",
       "0            Meditron  \n",
       "0            Meditron  \n",
       "0            LittC2SE  \n",
       "0            Litt3200  \n",
       "0            Litt3200  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_list = [] #list for names\n",
    "rec_annotations = [] \n",
    "rec_annotations_dict = {}\n",
    "for s in filenames: #apply function to all the audio files\n",
    "    (i,a) = Extract_Annotation_Data(s, root) #get recording info and recording annotations\n",
    "    i_list.append(i) #form a list of all the recording info\n",
    "    rec_annotations.append(a) #form a list of all the recording annotations\n",
    "    rec_annotations_dict[s] = a #connect the audio files to their respective recording annotations by making a dictionary\n",
    "recording_info = pd.concat(i_list, axis = 0) #make a datafram from i_list with the data of recording info\n",
    "recording_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rec_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'101_1b1_Pr_sc_Meditron':      Start     End  Crackles  Wheezes\n",
       " 0    0.036   1.264         0        0\n",
       " 1    1.264   3.422         0        0\n",
       " 2    3.422   5.550         0        0\n",
       " 3    5.550   7.436         0        0\n",
       " 4    7.436   9.221         0        0\n",
       " 5    9.221  11.264         0        0\n",
       " 6   11.264  13.264         0        0\n",
       " 7   13.264  15.179         0        0\n",
       " 8   15.179  17.207         0        0\n",
       " 9   17.207  19.179         0        0\n",
       " 10  19.179  19.936         0        0,\n",
       " '102_1b1_Ar_sc_Meditron':      Start     End  Crackles  Wheezes\n",
       " 0    0.264   1.736         0        0\n",
       " 1    1.736   3.293         0        0\n",
       " 2    3.293   5.307         0        0\n",
       " 3    5.307   6.636         0        0\n",
       " 4    6.636   8.036         0        0\n",
       " 5    8.036   9.607         0        0\n",
       " 6    9.607  11.036         0        0\n",
       " 7   11.036  13.036         0        0\n",
       " 8   13.036  14.664         0        0\n",
       " 9   14.664  16.393         0        0\n",
       " 10  16.393  17.893         0        0\n",
       " 11  17.893  19.593         0        0\n",
       " 12  19.593  19.964         0        0,\n",
       " '103_2b2_Ar_mc_LittC2SE':     Start     End  Crackles  Wheezes\n",
       " 0   0.364   3.250         0        1\n",
       " 1   3.250   6.636         0        0\n",
       " 2   6.636  11.179         0        1\n",
       " 3  11.179  14.250         0        1\n",
       " 4  14.250  16.993         0        1\n",
       " 5  16.993  19.979         0        0,\n",
       " '104_1b1_Al_sc_Litt3200':      Start      End  Crackles  Wheezes\n",
       " 0   0.0000   1.8771         0        0\n",
       " 1   1.8771   3.7543         0        0\n",
       " 2   3.7543   6.1071         0        0\n",
       " 3   6.1071   8.2502         0        0\n",
       " 4   8.2502  12.6180         0        0\n",
       " 5  12.6180  15.8560         0        0,\n",
       " '104_1b1_Ar_sc_Litt3200':        Start       End  Crackles  Wheezes\n",
       " 0    0.00000   0.54469         0        1\n",
       " 1    0.54469   2.96280         0        1\n",
       " 2    2.96280   5.10850         0        1\n",
       " 3    5.10850   7.21720         0        1\n",
       " 4    7.21720   9.14420         0        1\n",
       " 5    9.14420  10.67500         0        1\n",
       " 6   10.67500  12.37100         0        1\n",
       " 7   12.37100  14.38100         0        1\n",
       " 8   14.38100  16.53500         0        1\n",
       " 9   16.53500  19.04800         0        1\n",
       " 10  19.04800  22.17600         0        0\n",
       " 11  22.17600  22.95100         0        0\n",
       " 12  22.95100  24.66400         0        0\n",
       " 13  24.66400  25.58400         0        0,\n",
       " '104_1b1_Ll_sc_Litt3200':       Start      End  Crackles  Wheezes\n",
       " 0   0.94188   2.8018         0        0\n",
       " 1   2.80180   4.6915         0        0\n",
       " 2   4.69150   6.7065         0        0\n",
       " 3   6.70650   8.8287         0        0\n",
       " 4   8.82870  10.3960         1        0\n",
       " 5  10.39600  12.7210         0        0\n",
       " 6  12.72100  18.4800         0        0,\n",
       " '104_1b1_Lr_sc_Litt3200':      Start      End  Crackles  Wheezes\n",
       " 0  0.74635   2.6365         0        0\n",
       " 1  2.63650   4.2164         0        0\n",
       " 2  4.21640   6.4167         0        0\n",
       " 3  6.41670   8.8302         0        0\n",
       " 4  8.83020  15.0240         0        0,\n",
       " '104_1b1_Pl_sc_Litt3200':       Start      End  Crackles  Wheezes\n",
       " 0    0.0000   1.0665         0        0\n",
       " 1    1.0665   2.5256         0        0\n",
       " 2    2.5256   4.7475         0        0\n",
       " 3    4.7475   7.2102         0        0\n",
       " 4    7.2102  10.0620         0        0\n",
       " 5   10.0620  10.8800         0        0\n",
       " 6   10.8800  11.6320         0        0\n",
       " 7   11.6320  13.1350         0        0\n",
       " 8   13.1350  16.1650         0        0\n",
       " 9   16.1650  17.8050         0        0\n",
       " 10  17.8050  20.2120         0        0\n",
       " 11  20.2120  21.7900         0        0\n",
       " 12  21.7900  22.9600         0        0,\n",
       " '104_1b1_Pr_sc_Litt3200':      Start      End  Crackles  Wheezes\n",
       " 0   2.6828   5.7942         0        0\n",
       " 1   5.7942   7.8379         0        0\n",
       " 2   7.8379  10.1990         0        0\n",
       " 3  10.1990  12.8170         0        0\n",
       " 4  12.8170  15.0060         0        0\n",
       " 5  15.0060  18.4390         0        0\n",
       " 6  18.4390  19.6330         0        0\n",
       " 7  19.6330  20.3870         0        0\n",
       " 8  20.3870  22.2090         0        0\n",
       " 9  22.2090  23.7280         0        0,\n",
       " '105_1b1_Tc_sc_Meditron':     Start     End  Crackles  Wheezes\n",
       " 0   0.036   2.279         0        0\n",
       " 1   2.279   4.879         0        0\n",
       " 2   4.879   7.507         0        0\n",
       " 3   7.507  10.336         0        0\n",
       " 4  10.336  13.364         0        0\n",
       " 5  13.364  16.179         0        0\n",
       " 6  16.179  19.007         0        0\n",
       " 7  19.007  19.907         0        0,\n",
       " '106_2b1_Pl_mc_LittC2SE':     Start     End  Crackles  Wheezes\n",
       " 0   0.036   2.164         1        0\n",
       " 1   2.164   4.621         1        0\n",
       " 2   4.621   7.179         0        0\n",
       " 3   7.179   9.636         1        0\n",
       " 4   9.636  12.007         1        0\n",
       " 5  12.007  14.407         1        0\n",
       " 6  14.407  16.793         1        0\n",
       " 7  16.793  19.207         1        0\n",
       " 8  19.207  19.964         1        0,\n",
       " '106_2b1_Pr_mc_LittC2SE':     Start     End  Crackles  Wheezes\n",
       " 0   0.064   2.079         0        1\n",
       " 1   2.079   4.579         0        1\n",
       " 2   4.579   7.093         0        0\n",
       " 3   7.093   9.607         0        1\n",
       " 4   9.607  12.021         0        1\n",
       " 5  12.021  14.336         0        1\n",
       " 6  14.336  16.807         0        1\n",
       " 7  16.807  19.121         0        1\n",
       " 8  19.121  19.979         0        0,\n",
       " '107_2b3_Al_mc_AKGC417L':     Start     End  Crackles  Wheezes\n",
       " 0   0.887   2.601         1        0\n",
       " 1   2.601   5.327         1        0\n",
       " 2   5.327   7.923         1        0\n",
       " 3   7.923  10.530         1        0\n",
       " 4  10.530  13.196         1        0\n",
       " 5  13.196  15.565         1        0\n",
       " 6  15.565  18.054         1        0\n",
       " 7  18.054  19.101         0        0,\n",
       " '107_2b3_Ar_mc_AKGC417L':     Start     End  Crackles  Wheezes\n",
       " 0   0.887   2.601         1        0\n",
       " 1   2.601   5.327         1        1\n",
       " 2   5.327   7.923         1        1\n",
       " 3   7.923  10.530         1        1\n",
       " 4  10.530  13.196         1        1\n",
       " 5  13.196  15.565         1        1\n",
       " 6  15.565  18.054         1        1\n",
       " 7  18.054  19.101         1        1,\n",
       " '107_2b3_Ll_mc_AKGC417L':     Start     End  Crackles  Wheezes\n",
       " 0   0.887   2.601         1        0\n",
       " 1   2.601   5.327         1        0\n",
       " 2   5.327   7.923         1        0\n",
       " 3   7.923  10.530         1        0\n",
       " 4  10.530  13.196         1        0\n",
       " 5  13.196  15.565         1        0\n",
       " 6  15.565  18.054         1        0\n",
       " 7  18.054  19.101         1        0,\n",
       " '107_2b3_Lr_mc_AKGC417L':     Start     End  Crackles  Wheezes\n",
       " 0   0.887   2.601         0        0\n",
       " 1   2.601   5.327         1        0\n",
       " 2   5.327   7.923         1        0\n",
       " 3   7.923  10.530         1        0\n",
       " 4  10.530  13.196         1        0\n",
       " 5  13.196  15.565         1        0\n",
       " 6  15.565  18.054         1        0\n",
       " 7  18.054  19.101         1        0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_annotations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "101df59261909482911400c0869f90cd300d36f3"
   },
   "outputs": [],
   "source": [
    "no_label_list = [] \n",
    "crack_list = []\n",
    "wheeze_list = []\n",
    "both_sym_list = []\n",
    "filename_list = []\n",
    "for f in filenames: #go through all filenames\n",
    "    d = rec_annotations_dict[f] \n",
    "    #d is the annotation data of that file from dictionay rec_annotations_dict\n",
    "    no_labels = len(d[(d['Crackles'] == 0) & (d['Wheezes'] == 0)].index) #get total none files\n",
    "    n_crackles = len(d[(d['Crackles'] == 1) & (d['Wheezes'] == 0)].index)\n",
    "    n_wheezes = len(d[(d['Crackles'] == 0) & (d['Wheezes'] == 1)].index)\n",
    "    both_sym = len(d[(d['Crackles'] == 1) & (d['Wheezes'] == 1)].index)\n",
    "    no_label_list.append(no_labels)\n",
    "    crack_list.append(n_crackles)\n",
    "    wheeze_list.append(n_wheezes)\n",
    "    both_sym_list.append(both_sym) \n",
    "    filename_list.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "92e261fa3987a54f8ce52ff93fbcf2289ac20faf"
   },
   "outputs": [],
   "source": [
    "#file_label_df will have total cycles under 'no label' ,'crakles only' ,'wheezes only', 'crackles and wheezees' \n",
    "file_label_df = pd.DataFrame(data = {'filename':filename_list, 'no label':no_label_list, 'crackles only':crack_list, 'wheezes only':wheeze_list, 'crackles and wheezees':both_sym_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>no label</th>\n",
       "      <th>crackles only</th>\n",
       "      <th>wheezes only</th>\n",
       "      <th>crackles and wheezees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101_1b1_Pr_sc_Meditron</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102_1b1_Ar_sc_Meditron</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103_2b2_Ar_mc_LittC2SE</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104_1b1_Al_sc_Litt3200</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104_1b1_Ar_sc_Litt3200</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 filename  no label  crackles only  wheezes only  \\\n",
       "0  101_1b1_Pr_sc_Meditron        11              0             0   \n",
       "1  102_1b1_Ar_sc_Meditron        13              0             0   \n",
       "2  103_2b2_Ar_mc_LittC2SE         2              0             4   \n",
       "3  104_1b1_Al_sc_Litt3200         6              0             0   \n",
       "4  104_1b1_Ar_sc_Litt3200         4              0            10   \n",
       "\n",
       "   crackles and wheezees  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_label_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating total cycles\n",
    "Totalcycles = file_label_df[\"no label\"].sum()+file_label_df[\"crackles only\"].sum()+file_label_df[\"wheezes only\"].sum()+file_label_df[\"crackles and wheezees\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    }
   ],
   "source": [
    "print(Totalcycles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c91a8fed39a97efa50dfb4b4e834008efe9e713f"
   },
   "source": [
    "# Distribution of data classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "26e1727c204af6104d584c3088daa638e8ed6227",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#w_labels will have the total number of cycles for every category of noise\n",
    "w_labels = file_label_df[(file_label_df['crackles only'] != 0) | (file_label_df['wheezes only'] != 0) | (file_label_df['crackles and wheezees'] != 0)]\n",
    "#file_label_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename                 101_1b1_Pr_sc_Meditron102_1b1_Ar_sc_Meditron10...\n",
       "no label                                                                83\n",
       "crackles only                                                           32\n",
       "wheezes only                                                            21\n",
       "crackles and wheezees                                                    7\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add all the values in the column of dataframe\n",
    "file_label_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>no label</th>\n",
       "      <th>crackles only</th>\n",
       "      <th>wheezes only</th>\n",
       "      <th>crackles and wheezees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103_2b2_Ar_mc_LittC2SE</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104_1b1_Ar_sc_Litt3200</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>104_1b1_Ll_sc_Litt3200</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>106_2b1_Pl_mc_LittC2SE</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>106_2b1_Pr_mc_LittC2SE</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filename  no label  crackles only  wheezes only  \\\n",
       "2   103_2b2_Ar_mc_LittC2SE         2              0             4   \n",
       "4   104_1b1_Ar_sc_Litt3200         4              0            10   \n",
       "5   104_1b1_Ll_sc_Litt3200         6              1             0   \n",
       "10  106_2b1_Pl_mc_LittC2SE         1              8             0   \n",
       "11  106_2b1_Pr_mc_LittC2SE         2              0             7   \n",
       "\n",
       "    crackles and wheezees  \n",
       "2                       0  \n",
       "4                       0  \n",
       "5                       0  \n",
       "10                      0  \n",
       "11                      0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4288dfa4a454a3626499348b48c490ae9523b4ec"
   },
   "source": [
    "# Utility functions for reading .wav files (especially pesky 24bit .wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "0595b1640a188ca09640694b48a876ce6df41944"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Wave_write.__del__ at 0x00000211C14F90D8>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Abhijeet\\Anaconda3\\lib\\wave.py\", line 327, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\Abhijeet\\Anaconda3\\lib\\wave.py\", line 445, in close\n",
      "    self._ensure_header_written(0)\n",
      "  File \"C:\\Users\\Abhijeet\\Anaconda3\\lib\\wave.py\", line 463, in _ensure_header_written\n",
      "    raise Error('# channels not specified')\n",
      "wave.Error: # channels not specified\n"
     ]
    }
   ],
   "source": [
    "import wave #to read in the wave files\n",
    "import math \n",
    "import scipy.io.wavfile as wf\n",
    "#wave file reader\n",
    "\n",
    "#resample\n",
    "#Will resample all files to the target sample rate and produce a 32bit float array \n",
    "\n",
    "#reads files takes input filename and target rate it is calling all funcitons ahead \n",
    "def read_wav_file(str_filename, target_rate): \n",
    "    wav = wave.open(str_filename, mode = 'wb')\n",
    "    (sample_rate, data) = extract2FloatArr(wav,str_filename) #get present sample rate of wav, this is a custom function created ahead\n",
    "    \n",
    "    if (sample_rate != target_rate): #if it isn't what the target sample rate is then resample\n",
    "        ( _ , data) = resample(sample_rate, data, target_rate) #call the function to resample\n",
    "        \n",
    "    wav.close()\n",
    "    return (target_rate, data.astype(np.float32)) #return the resampled file\n",
    "\n",
    "def resample(current_rate, data, target_rate): #will resample the wav audio\n",
    "    x_original = np.linspace(0,100,len(data))\n",
    "    x_resampled = np.linspace(0,100, int(len(data) * (target_rate / current_rate)))\n",
    "    resampled = np.interp(x_resampled, x_original, data)\n",
    "    return (target_rate, resampled.astype(np.float32))\n",
    "\n",
    "\n",
    "#function to load the audio file in float and fetch the current sample rate\n",
    "# -> (sample_rate, data)\n",
    "def extract2FloatArr(lp_wave, str_filename): #this function is created get the data in form ofarray\n",
    "    (bps, channels) = bitrate_channels(lp_wave)\n",
    "    \n",
    "    if bps in [1,2,4]:\n",
    "        (rate, data) = wf.read(str_filename)\n",
    "        divisor_dict = {1:255, 2:32768}\n",
    "        if bps in [1,2]:\n",
    "            divisor = divisor_dict[bps]\n",
    "            data = np.divide(data, float(divisor)) #clamp to [0.0,1.0]        \n",
    "        return (rate, data)\n",
    "    \n",
    "    elif bps == 3: \n",
    "        #24bpp wave\n",
    "        return read24bitwave(lp_wave)\n",
    "    \n",
    "    else:\n",
    "        raise Exception('Unrecognized wave format: {} bytes per sample'.format(bps))\n",
    "        \n",
    "#Note: This function truncates the 24 bit samples to 16 bits of precision\n",
    "#Reads a wave object returned by the wave.read() method\n",
    "#Returns the sample rate, as well as the audio in the form of a 32 bit float numpy array\n",
    "#(sample_rate:float, audio_data: float[])\n",
    "def read24bitwave(lp_wave):\n",
    "    nFrames = lp_wave.getnframes()\n",
    "    buf = lp_wave.readframes(nFrames)\n",
    "    reshaped = np.frombuffer(buf, np.int8).reshape(nFrames,-1)\n",
    "    short_output = np.empty((nFrames, 2), dtype = np.int8)\n",
    "    short_output[:,:] = reshaped[:, -2:]\n",
    "    short_output = short_output.view(np.int16)\n",
    "    return (lp_wave.getframerate(), np.divide(short_output, 32768).reshape(-1))  #return numpy array to save memory via array slicing\n",
    "\n",
    "def bitrate_channels(lp_wave):\n",
    "    bps = (lp_wave.getsampwidth() / lp_wave.getnchannels()) #bytes per sample\n",
    "    return (bps, lp_wave.getnchannels())\n",
    "\n",
    "def slice_data(start, end, raw_data,  sample_rate):\n",
    "    max_ind = len(raw_data) \n",
    "    start_ind = min(int(start * sample_rate), max_ind)\n",
    "    end_ind = min(int(end * sample_rate), max_ind)\n",
    "    return raw_data[start_ind: end_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d075d96d6f2dd83f26f17568ad355d815f8003ba"
   },
   "source": [
    "# Distribution of respiratory cycle lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[     Start     End  Crackles  Wheezes\n",
       " 0    0.036   1.264         0        0\n",
       " 1    1.264   3.422         0        0\n",
       " 2    3.422   5.550         0        0\n",
       " 3    5.550   7.436         0        0\n",
       " 4    7.436   9.221         0        0\n",
       " 5    9.221  11.264         0        0\n",
       " 6   11.264  13.264         0        0\n",
       " 7   13.264  15.179         0        0\n",
       " 8   15.179  17.207         0        0\n",
       " 9   17.207  19.179         0        0\n",
       " 10  19.179  19.936         0        0,      Start     End  Crackles  Wheezes\n",
       " 0    0.264   1.736         0        0\n",
       " 1    1.736   3.293         0        0\n",
       " 2    3.293   5.307         0        0\n",
       " 3    5.307   6.636         0        0\n",
       " 4    6.636   8.036         0        0\n",
       " 5    8.036   9.607         0        0\n",
       " 6    9.607  11.036         0        0\n",
       " 7   11.036  13.036         0        0\n",
       " 8   13.036  14.664         0        0\n",
       " 9   14.664  16.393         0        0\n",
       " 10  16.393  17.893         0        0\n",
       " 11  17.893  19.593         0        0\n",
       " 12  19.593  19.964         0        0,     Start     End  Crackles  Wheezes\n",
       " 0   0.364   3.250         0        1\n",
       " 1   3.250   6.636         0        0\n",
       " 2   6.636  11.179         0        1\n",
       " 3  11.179  14.250         0        1\n",
       " 4  14.250  16.993         0        1\n",
       " 5  16.993  19.979         0        0,      Start      End  Crackles  Wheezes\n",
       " 0   0.0000   1.8771         0        0\n",
       " 1   1.8771   3.7543         0        0\n",
       " 2   3.7543   6.1071         0        0\n",
       " 3   6.1071   8.2502         0        0\n",
       " 4   8.2502  12.6180         0        0\n",
       " 5  12.6180  15.8560         0        0,        Start       End  Crackles  Wheezes\n",
       " 0    0.00000   0.54469         0        1\n",
       " 1    0.54469   2.96280         0        1\n",
       " 2    2.96280   5.10850         0        1\n",
       " 3    5.10850   7.21720         0        1\n",
       " 4    7.21720   9.14420         0        1\n",
       " 5    9.14420  10.67500         0        1\n",
       " 6   10.67500  12.37100         0        1\n",
       " 7   12.37100  14.38100         0        1\n",
       " 8   14.38100  16.53500         0        1\n",
       " 9   16.53500  19.04800         0        1\n",
       " 10  19.04800  22.17600         0        0\n",
       " 11  22.17600  22.95100         0        0\n",
       " 12  22.95100  24.66400         0        0\n",
       " 13  24.66400  25.58400         0        0,       Start      End  Crackles  Wheezes\n",
       " 0   0.94188   2.8018         0        0\n",
       " 1   2.80180   4.6915         0        0\n",
       " 2   4.69150   6.7065         0        0\n",
       " 3   6.70650   8.8287         0        0\n",
       " 4   8.82870  10.3960         1        0\n",
       " 5  10.39600  12.7210         0        0\n",
       " 6  12.72100  18.4800         0        0,      Start      End  Crackles  Wheezes\n",
       " 0  0.74635   2.6365         0        0\n",
       " 1  2.63650   4.2164         0        0\n",
       " 2  4.21640   6.4167         0        0\n",
       " 3  6.41670   8.8302         0        0\n",
       " 4  8.83020  15.0240         0        0,       Start      End  Crackles  Wheezes\n",
       " 0    0.0000   1.0665         0        0\n",
       " 1    1.0665   2.5256         0        0\n",
       " 2    2.5256   4.7475         0        0\n",
       " 3    4.7475   7.2102         0        0\n",
       " 4    7.2102  10.0620         0        0\n",
       " 5   10.0620  10.8800         0        0\n",
       " 6   10.8800  11.6320         0        0\n",
       " 7   11.6320  13.1350         0        0\n",
       " 8   13.1350  16.1650         0        0\n",
       " 9   16.1650  17.8050         0        0\n",
       " 10  17.8050  20.2120         0        0\n",
       " 11  20.2120  21.7900         0        0\n",
       " 12  21.7900  22.9600         0        0,      Start      End  Crackles  Wheezes\n",
       " 0   2.6828   5.7942         0        0\n",
       " 1   5.7942   7.8379         0        0\n",
       " 2   7.8379  10.1990         0        0\n",
       " 3  10.1990  12.8170         0        0\n",
       " 4  12.8170  15.0060         0        0\n",
       " 5  15.0060  18.4390         0        0\n",
       " 6  18.4390  19.6330         0        0\n",
       " 7  19.6330  20.3870         0        0\n",
       " 8  20.3870  22.2090         0        0\n",
       " 9  22.2090  23.7280         0        0,     Start     End  Crackles  Wheezes\n",
       " 0   0.036   2.279         0        0\n",
       " 1   2.279   4.879         0        0\n",
       " 2   4.879   7.507         0        0\n",
       " 3   7.507  10.336         0        0\n",
       " 4  10.336  13.364         0        0\n",
       " 5  13.364  16.179         0        0\n",
       " 6  16.179  19.007         0        0\n",
       " 7  19.007  19.907         0        0,     Start     End  Crackles  Wheezes\n",
       " 0   0.036   2.164         1        0\n",
       " 1   2.164   4.621         1        0\n",
       " 2   4.621   7.179         0        0\n",
       " 3   7.179   9.636         1        0\n",
       " 4   9.636  12.007         1        0\n",
       " 5  12.007  14.407         1        0\n",
       " 6  14.407  16.793         1        0\n",
       " 7  16.793  19.207         1        0\n",
       " 8  19.207  19.964         1        0,     Start     End  Crackles  Wheezes\n",
       " 0   0.064   2.079         0        1\n",
       " 1   2.079   4.579         0        1\n",
       " 2   4.579   7.093         0        0\n",
       " 3   7.093   9.607         0        1\n",
       " 4   9.607  12.021         0        1\n",
       " 5  12.021  14.336         0        1\n",
       " 6  14.336  16.807         0        1\n",
       " 7  16.807  19.121         0        1\n",
       " 8  19.121  19.979         0        0,     Start     End  Crackles  Wheezes\n",
       " 0   0.887   2.601         1        0\n",
       " 1   2.601   5.327         1        0\n",
       " 2   5.327   7.923         1        0\n",
       " 3   7.923  10.530         1        0\n",
       " 4  10.530  13.196         1        0\n",
       " 5  13.196  15.565         1        0\n",
       " 6  15.565  18.054         1        0\n",
       " 7  18.054  19.101         0        0,     Start     End  Crackles  Wheezes\n",
       " 0   0.887   2.601         1        0\n",
       " 1   2.601   5.327         1        1\n",
       " 2   5.327   7.923         1        1\n",
       " 3   7.923  10.530         1        1\n",
       " 4  10.530  13.196         1        1\n",
       " 5  13.196  15.565         1        1\n",
       " 6  15.565  18.054         1        1\n",
       " 7  18.054  19.101         1        1,     Start     End  Crackles  Wheezes\n",
       " 0   0.887   2.601         1        0\n",
       " 1   2.601   5.327         1        0\n",
       " 2   5.327   7.923         1        0\n",
       " 3   7.923  10.530         1        0\n",
       " 4  10.530  13.196         1        0\n",
       " 5  13.196  15.565         1        0\n",
       " 6  15.565  18.054         1        0\n",
       " 7  18.054  19.101         1        0,     Start     End  Crackles  Wheezes\n",
       " 0   0.887   2.601         0        0\n",
       " 1   2.601   5.327         1        0\n",
       " 2   5.327   7.923         1        0\n",
       " 3   7.923  10.530         1        0\n",
       " 4  10.530  13.196         1        0\n",
       " 5  13.196  15.565         1        0\n",
       " 6  15.565  18.054         1        0\n",
       " 7  18.054  19.101         1        0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "bc1f720697a0bff33f021b4ed1d1c9694200caff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest cycle:6.193800000000001\n",
      "shortest cycle:0.3710000000000022\n",
      "Fraction of samples less than 5 seconds:0.986013986013986\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "duration_list = [] #this will get the duration of every respiratory cycle\n",
    "for i in range(len(rec_annotations)):\n",
    "    current = rec_annotations[i]\n",
    "    duration = current['End'] - current['Start'] #get duration\n",
    "    duration_list.extend(duration) #add the duration to list\n",
    "\n",
    "duration_list = np.array(duration_list) #convert the list in numpy array\n",
    "plt.hist(duration_list, bins = 50) #convert the array into histogram\n",
    "print('longest cycle:{}'.format(max(duration_list))) #print longest cycle\n",
    "print('shortest cycle:{}'.format(min(duration_list))) #print shortest cycle\n",
    "threshold = 5 #why is threshold 5 is not something I know\n",
    "print('Fraction of samples less than {} seconds:{}'.format(threshold,\n",
    "                                                           np.sum(duration_list < threshold)/len(duration_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total respiration cycles\n",
    "len(duration_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7a44dbd5d5906f0e75a3fcb0dc520f5615600ece"
   },
   "source": [
    "# Mel spectrogram implementation (With VTLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "39cb6a31ccb2c4d9388dfa1f23a5973c65a9d5b4"
   },
   "outputs": [],
   "source": [
    "#read again what is happening here\n",
    "\n",
    "import scipy.signal\n",
    "\n",
    "#vtlp_params = (alpha, f_high) \n",
    "def sample2MelSpectrum(cycle_info, sample_rate, n_filters, vtlp_params):\n",
    "    n_rows = 175 # 7500 cutoff\n",
    "    n_window = 512 #~25 ms window\n",
    "    (f, t, Sxx) = scipy.signal.spectrogram(cycle_info[0],fs = sample_rate, nfft= n_window, nperseg=n_window)\n",
    "    Sxx = Sxx[:n_rows,:].astype(np.float32) #sift out coefficients above 7500hz, Sxx has 196 columns\n",
    "    mel_log = FFT2MelSpectrogram(f[:n_rows], Sxx, sample_rate, n_filters, vtlp_params)[1]\n",
    "    mel_min = np.min(mel_log)\n",
    "    mel_max = np.max(mel_log)\n",
    "    diff = mel_max - mel_min\n",
    "    norm_mel_log = (mel_log - mel_min) / diff if (diff > 0) else np.zeros(shape = (n_filters,Sxx.shape[1]))\n",
    "    if (diff == 0):\n",
    "        print('Error: sample data is completely empty')\n",
    "    labels = [cycle_info[1], cycle_info[2]] #crackles, wheezes flags\n",
    "    return (np.reshape(norm_mel_log, (n_filters,Sxx.shape[1],1)).astype(np.float32), # 196x64x1 matrix\n",
    "            label2onehot(labels)) \n",
    "        \n",
    "def Freq2Mel(freq):\n",
    "    return 1125 * np.log(1 + freq / 700)\n",
    "\n",
    "def Mel2Freq(mel):\n",
    "    exponents = mel / 1125\n",
    "    return 700 * (np.exp(exponents) - 1)\n",
    "\n",
    "#Tased on Jaitly & Hinton(2013)\n",
    "#Takes an array of the original mel spaced frequencies and returns a warped version of them\n",
    "def VTLP_shift(mel_freq, alpha, f_high, sample_rate):\n",
    "    nyquist_f = sample_rate / 2\n",
    "    warp_factor = min(alpha, 1)\n",
    "    threshold_freq = f_high * warp_factor / alpha\n",
    "    lower = mel_freq * alpha\n",
    "    higher = nyquist_f - (nyquist_f - mel_freq) * ((nyquist_f - f_high * warp_factor) / (nyquist_f - f_high * (warp_factor / alpha)))\n",
    "    \n",
    "    warped_mel = np.where(mel_freq <= threshold_freq, lower, higher)\n",
    "    return warped_mel.astype(np.float32)\n",
    "\n",
    "#mel_space_freq: the mel frequencies (HZ) of the filter banks, in addition to the two maximum and minimum frequency values\n",
    "#fft_bin_frequencies: the bin freqencies of the FFT output\n",
    "#Generates a 2d numpy array, with each row containing each filter bank\n",
    "def GenerateMelFilterBanks(mel_space_freq, fft_bin_frequencies):\n",
    "    n_filters = len(mel_space_freq) - 2\n",
    "    coeff = []\n",
    "    #Triangular filter windows\n",
    "    #ripped from http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/\n",
    "    for mel_index in range(n_filters):\n",
    "        m = int(mel_index + 1)\n",
    "        filter_bank = []\n",
    "        for f in fft_bin_frequencies:\n",
    "            if(f < mel_space_freq[m-1]):\n",
    "                hm = 0\n",
    "            elif(f < mel_space_freq[m]):\n",
    "                hm = (f - mel_space_freq[m-1]) / (mel_space_freq[m] - mel_space_freq[m-1])\n",
    "            elif(f < mel_space_freq[m + 1]):\n",
    "                hm = (mel_space_freq[m+1] - f) / (mel_space_freq[m + 1] - mel_space_freq[m])\n",
    "            else:\n",
    "                hm = 0\n",
    "            filter_bank.append(hm)\n",
    "        coeff.append(filter_bank)\n",
    "    return np.array(coeff, dtype = np.float32)\n",
    "        \n",
    "#Transform spectrogram into mel spectrogram -> (frequencies, spectrum)\n",
    "#vtlp_params = (alpha, f_high), vtlp will not be applied if set to None\n",
    "def FFT2MelSpectrogram(f, Sxx, sample_rate, n_filterbanks, vtlp_params = None):\n",
    "    (max_mel, min_mel)  = (Freq2Mel(max(f)), Freq2Mel(min(f)))\n",
    "    mel_bins = np.linspace(min_mel, max_mel, num = (n_filterbanks + 2))\n",
    "    #Convert mel_bins to corresponding frequencies in hz\n",
    "    mel_freq = Mel2Freq(mel_bins)\n",
    "    \n",
    "    if(vtlp_params is None):\n",
    "        filter_banks = GenerateMelFilterBanks(mel_freq, f)\n",
    "    else:\n",
    "        #Apply VTLP\n",
    "        (alpha, f_high) = vtlp_params\n",
    "        warped_mel = VTLP_shift(mel_freq, alpha, f_high, sample_rate)\n",
    "        filter_banks = GenerateMelFilterBanks(warped_mel, f)\n",
    "        \n",
    "    mel_spectrum = np.matmul(filter_banks, Sxx)\n",
    "    return (mel_freq[1:-1], np.log10(mel_spectrum  + float(10e-12)))\n",
    "    \n",
    "#labels proved too difficult to train (model keep convergining to statistical mean)\n",
    "#Flattened to onehot labels since the number of combinations is very low\n",
    "def label2onehot(c_w_flags):\n",
    "    c = c_w_flags[0]\n",
    "    w = c_w_flags[1]\n",
    "    if((c == False) & (w == False)):\n",
    "        return [1,0,0,0]\n",
    "    elif((c == True) & (w == False)):\n",
    "        return [0,1,0,0]\n",
    "    elif((c == False) & (w == True)):\n",
    "        return [0,0,1,0]\n",
    "    else:\n",
    "        return [0,0,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d4a75526cc7d116004ba0e18f1a0be153f5e91e6"
   },
   "source": [
    "# Data preparation utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "0019f4252e39cebcdb53e5a5f3ca98b2d1262e42"
   },
   "outputs": [],
   "source": [
    "#Used to split each individual sound file into separate sound clips containing one respiratory cycle each\n",
    "#output: [filename, (sample_data:np.array, start:float, end:float, crackles:bool(float), wheezes:bool(float)) (...) ]\n",
    "def get_sound_samples(recording_annotations, file_name, root, sample_rate): #load audio\n",
    "    sample_data = [file_name] #audio file\n",
    "    (rate, data) = read_wav_file(os.path.join(root, file_name + '.wav'), sample_rate) #get rate and data\n",
    "    \n",
    "    for i in range(len(recording_annotations.index)):\n",
    "        row = recording_annotations.loc[i]\n",
    "        start = row['Start']\n",
    "        end = row['End']\n",
    "        crackles = row['Crackles']\n",
    "        wheezes = row['Wheezes']\n",
    "        audio_chunk = slice_data(start, end, data, rate)\n",
    "        sample_data.append((audio_chunk, start,end,crackles,wheezes))\n",
    "    return sample_data\n",
    "\n",
    "#Fits each respiratory cycle into a fixed length audio clip, splits may be performed and zero padding is added if necessary\n",
    "#original:(arr,c,w) -> output:[(arr,c,w),(arr,c,w)]\n",
    "def split_and_pad(original, desiredLength, sampleRate): \n",
    "    output_buffer_length = int(desiredLength * sampleRate)\n",
    "    soundclip = original[0]\n",
    "    n_samples = len(soundclip)\n",
    "    total_length = n_samples / sampleRate #length of cycle in seconds\n",
    "    n_slices = int(math.ceil(total_length / desiredLength)) #get the minimum number of slices needed\n",
    "    samples_per_slice = n_samples // n_slices\n",
    "    src_start = 0 #Staring index of the samples to copy from the original buffer\n",
    "    output = [] #Holds the resultant slices\n",
    "    for i in range(n_slices):\n",
    "        src_end = min(src_start + samples_per_slice, n_samples)\n",
    "        length = src_end - src_start\n",
    "        copy = generate_padded_samples(soundclip[src_start:src_end], output_buffer_length)\n",
    "        output.append((copy, original[1], original[2]))\n",
    "        src_start += length\n",
    "    return output\n",
    "\n",
    "def generate_padded_samples(source, output_length):\n",
    "    copy = np.zeros(output_length, dtype = np.float32)\n",
    "    src_length = len(source)\n",
    "    frac = src_length / output_length\n",
    "    if(frac < 0.5):\n",
    "        #tile forward sounds to fill empty space\n",
    "        cursor = 0\n",
    "        while(cursor + src_length) < output_length:\n",
    "            copy[cursor:(cursor + src_length)] = source[:]\n",
    "            cursor += src_length\n",
    "    else:\n",
    "        copy[:src_length] = source[:]\n",
    "    #\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "24efa87087b3144117d988eb9efa40610fa1e602"
   },
   "source": [
    " # Data augmentation\n",
    " Two basic forms employed : audio stretching (speeding up or down)  as well as Vocal Tract Length perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "ddf33192a05fbcff53418e9a1bbf189a0f8931ff"
   },
   "outputs": [],
   "source": [
    "#Creates a copy of each time slice, but stretches or contracts it by a random amount\n",
    "def gen_time_stretch(original, sample_rate, max_percent_change):\n",
    "    stretch_amount = 1 + np.random.uniform(-1,1) * (max_percent_change / 100)\n",
    "    (_, stretched) = resample(sample_rate, original, int(sample_rate * stretch_amount)) \n",
    "    return stretched\n",
    "\n",
    "#Same as above, but applies it to a list of samples\n",
    "def augment_list(audio_with_labels, sample_rate, percent_change, n_repeats):\n",
    "    augmented_samples = []\n",
    "    for i in range(n_repeats):\n",
    "        addition = [(gen_time_stretch(t[0], sample_rate, percent_change), t[1], t[2] ) for t in audio_with_labels]\n",
    "        augmented_samples.extend(addition)\n",
    "    return augmented_samples\n",
    "\n",
    "#Takes a list of respiratory cycles, and splits and pads each cycle into fixed length buffers (determined by desiredLength(seconds))\n",
    "#Then takes the split and padded sample and transforms it into a mel spectrogram\n",
    "#VTLP_alpha_range = [Lower, Upper] (Bounds of random selection range), \n",
    "#VTLP_high_freq_range = [Lower, Upper] (-)\n",
    "#output:[(arr:float[],c:float_bool,w:float_bool),(arr,c,w)]\n",
    "def split_and_pad_and_apply_mel_spect(original, desiredLength, sampleRate, VTLP_alpha_range = None, VTLP_high_freq_range = None, n_repeats = 1):\n",
    "    output = []\n",
    "    for i in range(n_repeats):\n",
    "        for d in original:\n",
    "            lst_result = split_and_pad(d, desiredLength, sampleRate) #Time domain\n",
    "            if( (VTLP_alpha_range is None) | (VTLP_high_freq_range is None) ):\n",
    "                #Do not apply VTLP\n",
    "                VTLP_params = None\n",
    "            else:\n",
    "                #Randomly generate VLTP parameters\n",
    "                alpha = np.random.uniform(VTLP_alpha_range[0], VTLP_alpha_range[1])\n",
    "                high_freq = np.random.uniform(VTLP_high_freq_range[0], VTLP_high_freq_range[1])\n",
    "                VTLP_params = (alpha, high_freq)\n",
    "            freq_result = [sample2MelSpectrum(d, sampleRate, 50, VTLP_params) for d in lst_result] #Freq domain\n",
    "            output.extend(freq_result)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['101_1b1_Pr_sc_Meditron',\n",
       " '102_1b1_Ar_sc_Meditron',\n",
       " '103_2b2_Ar_mc_LittC2SE',\n",
       " '104_1b1_Al_sc_Litt3200',\n",
       " '104_1b1_Ar_sc_Litt3200',\n",
       " '104_1b1_Ll_sc_Litt3200',\n",
       " '104_1b1_Lr_sc_Litt3200',\n",
       " '104_1b1_Pl_sc_Litt3200',\n",
       " '104_1b1_Pr_sc_Litt3200',\n",
       " '105_1b1_Tc_sc_Meditron',\n",
       " '106_2b1_Pl_mc_LittC2SE',\n",
       " '106_2b1_Pr_mc_LittC2SE',\n",
       " '107_2b3_Al_mc_AKGC417L',\n",
       " '107_2b3_Ar_mc_AKGC417L',\n",
       " '107_2b3_Ll_mc_AKGC417L',\n",
       " '107_2b3_Lr_mc_AKGC417L']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "f0c71f1dfc7b6a4cd1df05c116b47295687e4b33"
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "sample width not set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-fee198d5c65f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstr_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#take a name from list of file names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlp_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_sound_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrec_annotations_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr_file\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m22000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlp_cycles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlp_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msoundclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlp_cycles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-35611f7563f6>\u001b[0m in \u001b[0;36mget_sound_samples\u001b[1;34m(recording_annotations, file_name, root, sample_rate)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_sound_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecording_annotations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#load audio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msample_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#audio file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_wav_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#get rate and data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecording_annotations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-17cf05cd4f52>\u001b[0m in \u001b[0;36mread_wav_file\u001b[1;34m(str_filename, target_rate)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_wav_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mwav\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract2FloatArr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr_filename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#get present sample rate of wav, this is a custom function created ahead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msample_rate\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtarget_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#if it isn't what the target sample rate is then resample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-17cf05cd4f52>\u001b[0m in \u001b[0;36mextract2FloatArr\u001b[1;34m(lp_wave, str_filename)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# -> (sample_rate, data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract2FloatArr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlp_wave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#this function is created get the data in form ofarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mbps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbitrate_channels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlp_wave\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbps\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-17cf05cd4f52>\u001b[0m in \u001b[0;36mbitrate_channels\u001b[1;34m(lp_wave)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbitrate_channels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlp_wave\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mbps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlp_wave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsampwidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlp_wave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnchannels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#bytes per sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlp_wave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnchannels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\wave.py\u001b[0m in \u001b[0;36mgetsampwidth\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetsampwidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampwidth\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sample width not set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampwidth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mError\u001b[0m: sample width not set"
     ]
    }
   ],
   "source": [
    "str_file = filenames[12] #take a name from list of file names\n",
    "lp_test = get_sound_samples(rec_annotations_dict[str_file], str_file, root, 22000)\n",
    "lp_cycles = [(d[0], d[3], d[4]) for d in lp_test[1:]]\n",
    "soundclip = lp_cycles[1][0]\n",
    "\n",
    "n_window = 512\n",
    "sample_rate = 22000\n",
    "(f, t, Sxx) = scipy.signal.spectrogram(soundclip, fs = 22000, nfft= n_window, nperseg=n_window)\n",
    "print(sum(f < 7000))\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.subplot(1,2,1)\n",
    "mel_banks = FFT2MelSpectrogram(f[:175], Sxx[:175,:], sample_rate, 50)[1]\n",
    "plt.imshow(mel_banks, aspect = 1)\n",
    "plt.title('No VTLP')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "mel_banks = FFT2MelSpectrogram(f[:175], Sxx[:175,:], sample_rate, 50, vtlp_params = (0.9,3500))[1]\n",
    "plt.imshow(mel_banks, aspect = 1)\n",
    "plt.title('With VTLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eee12319864b3551bfa459cf4e3ac034ffbd9463"
   },
   "source": [
    "# Utility used to import all training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "b373daadbf268f81e5d0bed77090166f7033f0b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Wave_write.__del__ at 0x00000211C14F90D8>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Abhijeet\\Anaconda3\\lib\\wave.py\", line 327, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\Abhijeet\\Anaconda3\\lib\\wave.py\", line 445, in close\n",
      "    self._ensure_header_written(0)\n",
      "  File \"C:\\Users\\Abhijeet\\Anaconda3\\lib\\wave.py\", line 463, in _ensure_header_written\n",
      "    raise Error('# channels not specified')\n",
      "wave.Error: # channels not specified\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def extract_all_training_samples(filenames, annotation_dict, root, target_rate, desired_length, train_test_ratio = 0.2):\n",
    "    cycle_list = []\n",
    "    c1 = 1\n",
    "    for file in filenames:\n",
    "        data = get_sound_samples(annotation_dict[file], file, root, target_rate)\n",
    "        cycles_with_labels = [(d[0], d[3], d[4]) for d in data[1:]]\n",
    "        name = str(c1)\n",
    "        write(name+'.wav', 44100, scaled)\n",
    "        cycle_list.extend(cycles_with_labels)\n",
    "        c1 = c1 + 1\n",
    "    \n",
    "    #Sort into respective classes\n",
    "    no_labels = [c for c in cycle_list if ((c[1] == 0) & (c[2] == 0))]\n",
    "    c_only = [c for c in cycle_list if ((c[1] == 1) & (c[2] == 0))] \n",
    "    w_only = [c for c in cycle_list if ((c[1] == 0) & (c[2] == 1))]\n",
    "    c_w = [c for c in cycle_list if ((c[1] == 1) & (c[2] == 1))]\n",
    "    \n",
    "    #Count of labels across all cycles, actual recording time also follows similar ratios\n",
    "    #none:3642\n",
    "    #crackles:1864 \n",
    "    #wheezes:886\n",
    "    #both:506\n",
    "    none_train, none_test = train_test_split(no_labels, test_size = train_test_ratio)\n",
    "    c_train, c_test  = train_test_split(c_only, test_size = train_test_ratio)\n",
    "    w_train, w_test  = train_test_split(w_only, test_size = train_test_ratio)\n",
    "    c_w_train, c_w_test  = train_test_split(c_w, test_size = train_test_ratio)\n",
    "    \n",
    "    #Training section (Data augmentation procedures)\n",
    "    #Augment w_only and c_w groups to match the size of c_only\n",
    "    #no_labels will be artifically reduced in the pipeline  later\n",
    "    w_stretch = w_train + augment_list(w_train, target_rate, 10 , 1) #\n",
    "    c_w_stretch = c_w_train + augment_list(c_w_train , target_rate, 10 , 1) \n",
    "    \n",
    "    #Split up cycles into sound clips with fixed lengths so they can be fed into a CNN\n",
    "    vtlp_alpha = [0.9,1.1]\n",
    "    vtlp_upper_freq = [3200,3800]\n",
    "    \n",
    "    train_none  = (split_and_pad_and_apply_mel_spect(none_train, desired_length, target_rate) +\n",
    "                   split_and_pad_and_apply_mel_spect(none_train, desired_length, target_rate, vtlp_alpha))\n",
    "    \n",
    "    train_c = (split_and_pad_and_apply_mel_spect(c_train, desired_length, target_rate) + \n",
    "               split_and_pad_and_apply_mel_spect(c_train, desired_length, target_rate, vtlp_alpha, vtlp_upper_freq, n_repeats = 3) ) #original samples + VTLP\n",
    "    \n",
    "    train_w = (split_and_pad_and_apply_mel_spect(w_stretch, desired_length, target_rate) + \n",
    "               split_and_pad_and_apply_mel_spect(w_stretch , desired_length, target_rate, vtlp_alpha , vtlp_upper_freq, n_repeats = 4)) #(original samples + time stretch) + VTLP\n",
    "    \n",
    "    train_c_w = (split_and_pad_and_apply_mel_spect(c_w_stretch, desired_length, target_rate) + \n",
    "                 split_and_pad_and_apply_mel_spect(c_w_stretch, desired_length, target_rate, vtlp_alpha , vtlp_upper_freq, n_repeats = 7)) #(original samples + time stretch * 2) + VTLP\n",
    "    \n",
    "    train_dict = {'none':train_none,'crackles':train_c,'wheezes':train_w, 'both':train_c_w}\n",
    "    \n",
    "    #test section \n",
    "    test_none  = split_and_pad_and_apply_mel_spect(none_test, desired_length, target_rate)\n",
    "    test_c = split_and_pad_and_apply_mel_spect(c_test, desired_length, target_rate)\n",
    "    test_w = split_and_pad_and_apply_mel_spect(w_test, desired_length, target_rate)\n",
    "    test_c_w = split_and_pad_and_apply_mel_spect(c_w_test, desired_length, target_rate)\n",
    "    \n",
    "    test_dict = {'none':test_none,'crackles':test_c,'wheezes':test_w, 'both':test_c_w}\n",
    "    \n",
    "    return [train_dict, test_dict]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_clips['both'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c49ed33718a224a03c414841706efd662cbe1985"
   },
   "outputs": [],
   "source": [
    "target_sample_rate = 22000 \n",
    "sample_length_seconds = 5\n",
    "sample_dict = extract_all_training_samples(filenames, rec_annotations_dict, root, target_sample_rate, sample_length_seconds) #sample rate lowered to meet memory constraints\n",
    "training_clips = sample_dict[0]\n",
    "test_clips = sample_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60cd8372f5e529d04abba33fed4f8559db2b8a35"
   },
   "outputs": [],
   "source": [
    "def print_sample_count(src_dict):\n",
    "    print('none:{}\\ncrackles:{}\\nwheezes:{}\\nboth:{}'.format(len(src_dict['none']),\n",
    "                                                        len(src_dict['crackles']),\n",
    "                                                        len(src_dict['wheezes']),\n",
    "                                                        len(src_dict['both'])))\n",
    "\n",
    "print('Samples Available')\n",
    "print('[Training set]')\n",
    "print_sample_count(training_clips)\n",
    "print('')\n",
    "print('[Test set]')\n",
    "print_sample_count(test_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_clips[\"crackles\"][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "547638c6b0e43da791fa0c73cea6bea1629c51b5"
   },
   "outputs": [],
   "source": [
    "#Example of tiled sound samples\n",
    "sample_height = training_clips['none'][0][0].shape[0]\n",
    "sample_width = training_clips['none'][0][0].shape[1]\n",
    "ind = 1\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.subplot(4,1,1)\n",
    "plt.imshow(training_clips['none'][ind][0].reshape(sample_height, sample_width))\n",
    "plt.title('None')\n",
    "plt.subplot(4,1,2)\n",
    "plt.imshow(training_clips['crackles'][ind][0].reshape(sample_height, sample_width))\n",
    "plt.title('Crackles')\n",
    "plt.subplot(4,1,3)\n",
    "plt.imshow(training_clips['wheezes'][ind][0].reshape(sample_height, sample_width))\n",
    "plt.title('Wheezes')\n",
    "plt.subplot(4,1,4)\n",
    "plt.imshow(training_clips['both'][ind][0].reshape(sample_height, sample_width))\n",
    "plt.title('Both')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ada1ead97b26f8eb051594f67d7dbe04096f4a7c"
   },
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79d3651b4b6c73d3cc7a33e6a434227529b1d171"
   },
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "#Interleaved sampling between classes\n",
    "#Used to ensure a balance of classes for the training set\n",
    "class data_generator():\n",
    "    #sound_clips = [[none],[crackles],[wheezes],[both]]\n",
    "    #strides: How far the sampling index for each category is advanced for each step\n",
    "    def __init__(self, sound_clips, strides):\n",
    "        self.clips = sound_clips  #clips = sound clips\n",
    "        self.strides = strides  #strides=strides\n",
    "        self.lengths = [len(arr) for arr in sound_clips]\n",
    "    \n",
    "    def n_available_samples(self):\n",
    "        return int(min(np.divide(self.lengths, self.strides))) * 4  #gives available samples\n",
    "    \n",
    "    def generate_keras(self, batch_size):  \n",
    "        cursor = [0,0,0,0]\n",
    "        while True:\n",
    "            i = 0\n",
    "            X,y = [],[]\n",
    "            for c in range(batch_size):\n",
    "                cat_length = self.lengths[i]\n",
    "                cat_clips = self.clips[i]\n",
    "                cat_stride = self.strides[i]\n",
    "                cat_advance = np.random.randint(low= 1,high = cat_stride + 1)\n",
    "                clip = cat_clips[(cursor[i] + cat_advance) % cat_length]\n",
    "                cursor[i] = (cursor[i] + self.strides[i]) % cat_length #advance cursor\n",
    "                s = (self.rollFFT(clip))\n",
    "                X.append(s[0])\n",
    "                y.append(s[1])\n",
    "                i = (i + 1) % 4 # go to next class\n",
    "            yield (np.reshape(X, (batch_size, sample_height, sample_width, 1)),\n",
    "                   np.reshape(y,(batch_size,4)))\n",
    "\n",
    "    #Transpose and wrap each array along the time axis\n",
    "    def rollFFT(self, fft_info):\n",
    "        fft = fft_info[0]\n",
    "        n_col = fft.shape[1]\n",
    "        pivot = np.random.randint(n_col)\n",
    "        return ((np.roll(fft, pivot, axis = 1)), fft_info[1])\n",
    "\n",
    "#Used for validation set\n",
    "class feed_all():\n",
    "    #sound_clips = [[none],[crackles],[wheezes],[both]]\n",
    "    #strides: How far the sampling index for each category is advanced for each step\n",
    "    def __init__(self, sound_clips, roll = True):\n",
    "        merged = []\n",
    "        for arr in sound_clips:\n",
    "            merged.extend(arr)\n",
    "        np.random.shuffle(merged)\n",
    "        self.clips = merged\n",
    "        self.nclips = len(merged)\n",
    "        self.roll = roll\n",
    "    #provides number of clips\n",
    "    def n_available_samples(self):\n",
    "        return len(self.clips)\n",
    "    \n",
    "    def generate_keras(self, batch_size):\n",
    "        i = 0\n",
    "        while True:\n",
    "            X,y = [],[]\n",
    "            for b in range(batch_size):\n",
    "                clip = self.clips[i]\n",
    "                i = (i + 1) % self.nclips\n",
    "                if(self.roll):\n",
    "                    s = (self.rollFFT(clip))\n",
    "                    X.append(s[0])\n",
    "                    y.append(s[1])\n",
    "                else:\n",
    "                    X.append(clip[0])\n",
    "                    y.append(clip[1])\n",
    "                    \n",
    "            yield (np.reshape(X, (batch_size,sample_height, sample_width,1)),\n",
    "                   np.reshape(y,(batch_size, 4)))\n",
    "\n",
    "    #Transpose and wrap each array along the time axis\n",
    "    def rollFFT(self, fft_info):\n",
    "        fft = fft_info[0]\n",
    "        n_col = fft.shape[1]\n",
    "        pivot = np.random.randint(n_col)\n",
    "        return ((np.roll(fft, pivot, axis = 1)), fft_info[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(w_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e09789c053f36f4b3863f2471b308b33608ea8eb"
   },
   "outputs": [],
   "source": [
    "[none_train, c_train, w_train, c_w_train] = [training_clips['none'], training_clips['crackles'], training_clips['wheezes'], training_clips['both']]\n",
    "[none_test, c_test, w_test,c_w_test] =  [test_clips['none'], test_clips['crackles'], test_clips['wheezes'], test_clips['both']]\n",
    "\n",
    "np.random.shuffle(none_train)\n",
    "np.random.shuffle(c_train)\n",
    "np.random.shuffle(w_train)\n",
    "np.random.shuffle(c_w_train)\n",
    "\n",
    "#Data pipeline objects\n",
    "train_gen = data_generator([none_train, c_train, w_train, c_w_train], [1,1,1,1])\n",
    "test_gen = feed_all([none_test, c_test, w_test,c_w_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "de804e4de514356b3428d5bd817d9e44478daa57"
   },
   "source": [
    "# CNN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(w_test[0][0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "405dedb74c832336bc72c0c17682f575e99ec904"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_epochs = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "21a2aa15b0ea5798ae2b796786ee583b8d60548e"
   },
   "outputs": [],
   "source": [
    "#Keras implementation\n",
    "from keras import Sequential\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, Dense, Activation, Dropout, MaxPool2D, Flatten, LeakyReLU\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, [7,11], strides = [2,2], padding = 'SAME', input_shape = (sample_height, sample_width, 1)))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(MaxPool2D(padding = 'SAME'))\n",
    "\n",
    "model.add(Conv2D(256, [5,5], padding = 'SAME'))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(MaxPool2D(padding = 'SAME'))\n",
    "\n",
    "model.add(Conv2D(256, [1,1], padding = 'SAME'))\n",
    "model.add(Conv2D(256, [3,3], padding = 'SAME'))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(MaxPool2D(padding = 'SAME'))\n",
    "\n",
    "model.add(Conv2D(512, [1,1], padding = 'SAME'))\n",
    "model.add(Conv2D(512, [3,3], padding = 'SAME',activation = 'relu'))\n",
    "model.add(Conv2D(512, [1,1], padding = 'SAME'))\n",
    "model.add(Conv2D(512, [3,3], padding = 'SAME', activation = 'relu'))\n",
    "model.add(MaxPool2D(padding = 'SAME'))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(4096, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(4, activation = 'softmax'))\n",
    "\n",
    "opt = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.00, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer =  opt , loss = 'categorical_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4856cd835f68b42499eea9c368e490553393328"
   },
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, show_shapes=True, show_layer_names = True)\n",
    "from IPython.display import Image\n",
    "Image(filename='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd95c81edb02b9e90c44a628a8b0c2dcd4bf7558"
   },
   "outputs": [],
   "source": [
    "stats = model.fit_generator(generator = train_gen.generate_keras(batch_size), \n",
    "                            steps_per_epoch = train_gen.n_available_samples() // batch_size,\n",
    "                            validation_data = test_gen.generate_keras(batch_size),\n",
    "                            validation_steps = test_gen.n_available_samples() // batch_size, \n",
    "                            epochs = n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db9acc2ae412bafe344d83c094ffcb0e2ca42c61"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(stats.history['acc'], label = 'training acc')\n",
    "plt.plot(stats.history['val_acc'], label = 'validation acc')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(stats.history['loss'], label = 'training loss')\n",
    "plt.plot(stats.history['val_loss'], label = 'validation loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39bd3325b3569af3f3d6a89d19750c8c573af0fb"
   },
   "outputs": [],
   "source": [
    "test_set = test_gen.generate_keras(test_gen.n_available_samples()).__next__()\n",
    "predictions = model.predict(test_set[0])\n",
    "predictions = np.argmax(predictions, axis = 1)\n",
    "labels = np.argmax(test_set[1], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmax(test_set[1], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3502b18c0ff81329872907c4277764b26689d0c3"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "63b8d408b222e3599d6b74f7c26f953c1dbcc1d8"
   },
   "outputs": [],
   "source": [
    "print(classification_report(labels, predictions, target_names = ['none','crackles','wheezes','both']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to split each individual sound file into separate sound clips containing one respiratory cycle each\n",
    "#output: [filename, (sample_data:np.array, start:float, end:float, crackles:bool(float), wheezes:bool(float)) (...) ]\n",
    "\n",
    "#this will return row, start, end, crackles and wheezes of each audio file\n",
    "def get_sound_samples(recording_annotations, file_name, root, sample_rate): #load audio\n",
    "    sample_data = [file_name] #audio file\n",
    "    (rate, data) = read_wav_file(os.path.join(root, file_name + '.wav'), sample_rate) #get rate and data\n",
    "    \n",
    "    for i in range(len(recording_annotations.index)):\n",
    "        row = recording_annotations.loc[i]\n",
    "        start = row['Start']\n",
    "        end = row['End']\n",
    "        crackles = row['Crackles']\n",
    "        wheezes = row['Wheezes']\n",
    "        audio_chunk = slice_data(start, end, data, rate)\n",
    "        sample_data.append((audio_chunk, start,end,crackles,wheezes))\n",
    "    return sample_data\n",
    "\n",
    "#Fits each respiratory cycle into a fixed length audio clip, splits may be performed and zero padding is added if necessary\n",
    "#original:(arr,c,w) -> output:[(arr,c,w),(arr,c,w)]\n",
    "\n",
    "#this will return the processed clip\n",
    "def split_and_pad(original, desiredLength, sampleRate): \n",
    "    output_buffer_length = int(desiredLength * sampleRate)\n",
    "    soundclip = original[0]\n",
    "    n_samples = len(soundclip)\n",
    "    total_length = n_samples / sampleRate #length of cycle in seconds\n",
    "    n_slices = int(math.ceil(total_length / desiredLength)) #get the minimum number of slices needed\n",
    "    samples_per_slice = n_samples // n_slices\n",
    "    src_start = 0 #Staring index of the samples to copy from the original buffer\n",
    "    output = [] #Holds the resultant slices\n",
    "    for i in range(n_slices):\n",
    "        src_end = min(src_start + samples_per_slice, n_samples)\n",
    "        length = src_end - src_start\n",
    "        copy = generate_padded_samples(soundclip[src_start:src_end], output_buffer_length)\n",
    "        output.append((copy, original[1], original[2]))\n",
    "        src_start += length\n",
    "    return output\n",
    "\n",
    "\n",
    "#this will generate padded samples which is called in split_and_pad function\n",
    "def generate_padded_samples(source, output_length):\n",
    "    copy = np.zeros(output_length, dtype = np.float32)\n",
    "    src_length = len(source)\n",
    "    frac = src_length / output_length\n",
    "    if(frac < 0.5):\n",
    "        #tile forward sounds to fill empty space\n",
    "        cursor = 0\n",
    "        while(cursor + src_length) < output_length:\n",
    "            copy[cursor:(cursor + src_length)] = source[:]\n",
    "            cursor += src_length\n",
    "    else:\n",
    "        copy[:src_length] = source[:]\n",
    "    #\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the audio files and resample\n",
    "import wave #to read in the wave files\n",
    "import math \n",
    "import scipy.io.wavfile as wf\n",
    "#wave file reader\n",
    "\n",
    "#resample\n",
    "#Will resample all files to the target sample rate and produce a 32bit float array \n",
    "\n",
    "#reads files takes input filename and target rate it is calling all funcitons ahead \n",
    "def read_wav_file(str_filename, target_rate): \n",
    "    wav = wave.open(str_filename, mode = 'r')\n",
    "    (sample_rate, data) = extract2FloatArr(wav,str_filename) #get present sample rate of wav, this is a custom function created ahead\n",
    "    \n",
    "    if (sample_rate != target_rate): #if it isn't what the target sample rate is then resample\n",
    "        ( _ , data) = resample(sample_rate, data, target_rate) #call the function to resample\n",
    "        \n",
    "    wav.close()\n",
    "    return (target_rate, data.astype(np.float32)) #return the resampled file\n",
    "\n",
    "def resample(current_rate, data, target_rate): #will resample the wav audio\n",
    "    x_original = np.linspace(0,100,len(data))\n",
    "    x_resampled = np.linspace(0,100, int(len(data) * (target_rate / current_rate)))\n",
    "    resampled = np.interp(x_resampled, x_original, data)\n",
    "    return (target_rate, resampled.astype(np.float32))\n",
    "\n",
    "\n",
    "#function to load the audio file in float and fetch the current sample rate\n",
    "# -> (sample_rate, data)\n",
    "def extract2FloatArr(lp_wave, str_filename): #this function is created get the data in form ofarray\n",
    "    (bps, channels) = bitrate_channels(lp_wave)\n",
    "    \n",
    "    if bps in [1,2,4]:\n",
    "        (rate, data) = wf.read(str_filename)\n",
    "        divisor_dict = {1:255, 2:32768}\n",
    "        if bps in [1,2]:\n",
    "            divisor = divisor_dict[bps]\n",
    "            data = np.divide(data, float(divisor)) #clamp to [0.0,1.0]        \n",
    "        return (rate, data)\n",
    "    \n",
    "    elif bps == 3: \n",
    "        #24bpp wave\n",
    "        return read24bitwave(lp_wave)\n",
    "    \n",
    "    else:\n",
    "        raise Exception('Unrecognized wave format: {} bytes per sample'.format(bps))\n",
    "        \n",
    "#Note: This function truncates the 24 bit samples to 16 bits of precision\n",
    "#Reads a wave object returned by the wave.read() method\n",
    "#Returns the sample rate, as well as the audio in the form of a 32 bit float numpy array\n",
    "#(sample_rate:float, audio_data: float[])\n",
    "def read24bitwave(lp_wave):\n",
    "    nFrames = lp_wave.getnframes()\n",
    "    buf = lp_wave.readframes(nFrames)\n",
    "    reshaped = np.frombuffer(buf, np.int8).reshape(nFrames,-1)\n",
    "    short_output = np.empty((nFrames, 2), dtype = np.int8)\n",
    "    short_output[:,:] = reshaped[:, -2:]\n",
    "    short_output = short_output.view(np.int16)\n",
    "    return (lp_wave.getframerate(), np.divide(short_output, 32768).reshape(-1))  #return numpy array to save memory via array slicing\n",
    "\n",
    "def bitrate_channels(lp_wave):\n",
    "    bps = (lp_wave.getsampwidth() / lp_wave.getnchannels()) #bytes per sample\n",
    "    return (bps, lp_wave.getnchannels())\n",
    "\n",
    "def slice_data(start, end, raw_data,  sample_rate):\n",
    "    max_ind = len(raw_data) \n",
    "    start_ind = min(int(start * sample_rate), max_ind)\n",
    "    end_ind = min(int(end * sample_rate), max_ind)\n",
    "    return raw_data[start_ind: end_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_time_stretch(original, sample_rate, max_percent_change):\n",
    "    stretch_amount = 1 + np.random.uniform(-1,1) * (max_percent_change / 100)\n",
    "    (_, stretched) = resample(sample_rate, original, int(sample_rate * stretch_amount)) \n",
    "    return stretched\n",
    "\n",
    "#Same as above, but applies it to a list of samples\n",
    "def augment_list(audio_with_labels, sample_rate, percent_change, n_repeats):\n",
    "    augmented_samples = []\n",
    "    for i in range(n_repeats):\n",
    "        addition = [(gen_time_stretch(t[0], sample_rate, percent_change), t[1], t[2] ) for t in audio_with_labels]\n",
    "        augmented_samples.extend(addition)\n",
    "    return augmented_samples\n",
    "\n",
    "#Takes a list of respiratory cycles, and splits and pads each cycle into fixed length buffers (determined by desiredLength(seconds))\n",
    "#Then takes the split and padded sample and transforms it into a mel spectrogram\n",
    "#VTLP_alpha_range = [Lower, Upper] (Bounds of random selection range), \n",
    "#VTLP_high_freq_range = [Lower, Upper] (-)\n",
    "#output:[(arr:float[],c:float_bool,w:float_bool),(arr,c,w)]\n",
    "def split_and_pad_and_apply_mel_spect(original, desiredLength, sampleRate, VTLP_alpha_range = None, VTLP_high_freq_range = None, n_repeats = 1):\n",
    "    output = []\n",
    "    for i in range(n_repeats):\n",
    "        for d in original:\n",
    "            lst_result = split_and_pad(d, desiredLength, sampleRate) #Time domain\n",
    "            if( (VTLP_alpha_range is None) | (VTLP_high_freq_range is None) ):\n",
    "                #Do not apply VTLP\n",
    "                VTLP_params = None\n",
    "            else:\n",
    "                #Randomly generate VLTP parameters\n",
    "                alpha = np.random.uniform(VTLP_alpha_range[0], VTLP_alpha_range[1])\n",
    "                high_freq = np.random.uniform(VTLP_high_freq_range[0], VTLP_high_freq_range[1])\n",
    "                VTLP_params = (alpha, high_freq)\n",
    "            freq_result = [sample2MelSpectrum(d, sampleRate, 50, VTLP_params) for d in lst_result] #Freq domain\n",
    "            output.extend(freq_result)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_training_samples(filenames, annotation_dict, root, target_rate, desired_length, train_test_ratio = 0.2):\n",
    "    cycle_list = []\n",
    "    for file in filenames:\n",
    "        data = get_sound_samples(annotation_dict[file], file, root, target_rate)\n",
    "        cycles_with_labels = [(d[0], d[3], d[4]) for d in data[1:]]\n",
    "        cycle_list.extend(cycles_with_labels)\n",
    "    \n",
    "    #Sort into respective classes\n",
    "    no_labels = [c for c in cycle_list if ((c[1] == 0) & (c[2] == 0))]\n",
    "    c_only = [c for c in cycle_list if ((c[1] == 1) & (c[2] == 0))] \n",
    "    w_only = [c for c in cycle_list if ((c[1] == 0) & (c[2] == 1))]\n",
    "    c_w = [c for c in cycle_list if ((c[1] == 1) & (c[2] == 1))]\n",
    "    \n",
    "    #Count of labels across all cycles, actual recording time also follows similar ratios\n",
    "    #none:3642\n",
    "    #crackles:1864 \n",
    "    #wheezes:886\n",
    "    #both:506\n",
    "    none_train, none_test = train_test_split(no_labels, test_size = train_test_ratio)\n",
    "    c_train, c_test  = train_test_split(c_only, test_size = train_test_ratio)\n",
    "    w_train, w_test  = train_test_split(w_only, test_size = train_test_ratio)\n",
    "    c_w_train, c_w_test  = train_test_split(c_w, test_size = train_test_ratio)\n",
    "    \n",
    "    #Training section (Data augmentation procedures)\n",
    "    #Augment w_only and c_w groups to match the size of c_only\n",
    "    #no_labels will be artifically reduced in the pipeline  later\n",
    "    w_stretch = w_train + augment_list(w_train, target_rate, 10 , 1) #\n",
    "    c_w_stretch = c_w_train + augment_list(c_w_train , target_rate, 10 , 1) \n",
    "    \n",
    "    #Split up cycles into sound clips with fixed lengths so they can be fed into a CNN\n",
    "    vtlp_alpha = [0.9,1.1]\n",
    "    vtlp_upper_freq = [3200,3800]\n",
    "    \n",
    "    train_none  = (split_and_pad_and_apply_mel_spect(none_train, desired_length, target_rate) +\n",
    "                   split_and_pad_and_apply_mel_spect(none_train, desired_length, target_rate, vtlp_alpha))\n",
    "    \n",
    "    train_c = (split_and_pad_and_apply_mel_spect(c_train, desired_length, target_rate) + \n",
    "               split_and_pad_and_apply_mel_spect(c_train, desired_length, target_rate, vtlp_alpha, vtlp_upper_freq, n_repeats = 3) ) #original samples + VTLP\n",
    "    \n",
    "    train_w = (split_and_pad_and_apply_mel_spect(w_stretch, desired_length, target_rate) + \n",
    "               split_and_pad_and_apply_mel_spect(w_stretch , desired_length, target_rate, vtlp_alpha , vtlp_upper_freq, n_repeats = 4)) #(original samples + time stretch) + VTLP\n",
    "    \n",
    "    train_c_w = (split_and_pad_and_apply_mel_spect(c_w_stretch, desired_length, target_rate) + \n",
    "                 split_and_pad_and_apply_mel_spect(c_w_stretch, desired_length, target_rate, vtlp_alpha , vtlp_upper_freq, n_repeats = 7)) #(original samples + time stretch * 2) + VTLP\n",
    "    \n",
    "    train_dict = {'none':train_none,'crackles':train_c,'wheezes':train_w, 'both':train_c_w}\n",
    "    \n",
    "    #test section \n",
    "    test_none  = split_and_pad_and_apply_mel_spect(none_test, desired_length, target_rate)\n",
    "    test_c = split_and_pad_and_apply_mel_spect(c_test, desired_length, target_rate)\n",
    "    test_w = split_and_pad_and_apply_mel_spect(w_test, desired_length, target_rate)\n",
    "    test_c_w = split_and_pad_and_apply_mel_spect(c_w_test, desired_length, target_rate)\n",
    "    \n",
    "    test_dict = {'none':test_none,'crackles':test_c,'wheezes':test_w, 'both':test_c_w}\n",
    "    \n",
    "    return [train_dict, test_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"testing/audio/\"\n",
    "filenames = [s.split('.')[0] for s in os.listdir(path = root) if '.txt' in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sample_rate = 22000 \n",
    "sample_length_seconds = 5\n",
    "sample_dict = extract_all_training_samples(filenames, rec_annotations_dict, root1, target_sample_rate, sample_length_seconds) #sample rate lowered to meet memory constraints\n",
    "training_clips = sample_dict[0]\n",
    "test_clips = sample_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_yaml\n",
    "yaml_file = open('model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "model = model_from_yaml(loaded_model_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_gen.generate_keras(test_gen.n_available_samples()).__next__()\n",
    "predictions = model.predict(test_set[0])\n",
    "predictions = np.argmax(predictions, axis = 1)\n",
    "labels = np.argmax(test_set[1], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write('pleasework.wav', 44100, test_set[0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read\n",
    "a = read(\"audio.wav\")\n",
    "b = np.array(a[1],dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play = get_sound_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s = pd.DataFrame(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "write('au0.wav', 44100, test_set[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.predict(test_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set[0][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.argmax(a,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s = pd.DataFrame(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read\n",
    "a = read(\"audio.wav\")\n",
    "b = np.array(a[1],dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = read_wav_file(\"audio.wav\", 22000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = split_and_pad_and_apply_mel_spect(b, 5, 22000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_training_samples(filenames, annotation_dict, root, target_rate, desired_length):\n",
    "    cycle_list = []\n",
    "    for file in filenames:\n",
    "        data = get_sound_samples(annotation_dict[file], file, root, target_rate)\n",
    "        cycles_with_labels = [(d[0], d[3], d[4]) for d in data[1:]]\n",
    "        cycle_list.extend(cycles_with_labels)\n",
    "    vtlp_alpha = [0.9,1.1]\n",
    "    vtlp_upper_freq = [3200,3800]\n",
    "    processed = split_and_pad_and_apply_mel_spect(cycle_list, desired_length, target_rate)\n",
    "    return processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_annotations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sample_rate = 22000\n",
    "desired_length = 5\n",
    "audio = extract_all_training_samples(filenames, rec_annotations_dict,root, target_sample_rate, desired_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = wave.open(\"107_2b3_Pl_mc_AKGC417L.wav\", mode = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "sample width not set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-9644cbd2e15b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'104_1b1_Al_sc_Litt3200'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m22000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_wav_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#get rate and data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-17cf05cd4f52>\u001b[0m in \u001b[0;36mread_wav_file\u001b[1;34m(str_filename, target_rate)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_wav_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mwav\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract2FloatArr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr_filename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#get present sample rate of wav, this is a custom function created ahead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msample_rate\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtarget_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#if it isn't what the target sample rate is then resample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-17cf05cd4f52>\u001b[0m in \u001b[0;36mextract2FloatArr\u001b[1;34m(lp_wave, str_filename)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# -> (sample_rate, data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract2FloatArr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlp_wave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#this function is created get the data in form ofarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mbps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbitrate_channels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlp_wave\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbps\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-17cf05cd4f52>\u001b[0m in \u001b[0;36mbitrate_channels\u001b[1;34m(lp_wave)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbitrate_channels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlp_wave\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mbps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlp_wave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsampwidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlp_wave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnchannels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#bytes per sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlp_wave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnchannels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\wave.py\u001b[0m in \u001b[0;36mgetsampwidth\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetsampwidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampwidth\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sample width not set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampwidth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mError\u001b[0m: sample width not set"
     ]
    }
   ],
   "source": [
    "file_name = '104_1b1_Al_sc_Litt3200'\n",
    "sample_rate = 22000\n",
    "(rate, data) = read_wav_file(os.path.join(root, file_name + '.wav'), sample_rate) #get rate and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
