{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-2-b89b6935f92d>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-b89b6935f92d>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    test_none  = split_and_pad_and_apply_mel_spect(none_test, desired_length, target_rate)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " #test section \n",
    "    test_none  = split_and_pad_and_apply_mel_spect(none_test, desired_length, target_rate)\n",
    "    test_c = split_and_pad_and_apply_mel_spect(c_test, desired_length, target_rate)\n",
    "    test_w = split_and_pad_and_apply_mel_spect(w_test, desired_length, target_rate)\n",
    "    test_c_w = split_and_pad_and_apply_mel_spect(c_w_test, desired_length, target_rate)\n",
    "    \n",
    "    test_dict = {'none':test_none,'crackles':test_c,'wheezes':test_w, 'both':test_c_w}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhijeet\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:473: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_string)\n"
     ]
    }
   ],
   "source": [
    "# load YAML and create model\n",
    "from keras.models import model_from_yaml\n",
    "yaml_file = open('model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "model = model_from_yaml(loaded_model_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c6e351209baf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_keras\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_available_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_gen' is not defined"
     ]
    }
   ],
   "source": [
    "test_set = test_gen.generate_keras(test_gen.n_available_samples()).__next__()\n",
    "test\n",
    "predictions = loaded_model.predict(test_set[0])\n",
    "predictions = np.argmax(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave #to read in the wave files\n",
    "import math \n",
    "import scipy.io.wavfile as wf\n",
    "#wave file reader\n",
    "\n",
    "#resample\n",
    "#Will resample all files to the target sample rate and produce a 32bit float array \n",
    "\n",
    "#reads files takes input filename and target rate it is calling all funcitons ahead \n",
    "def read_wav_file(str_filename, target_rate): \n",
    "    wav = wave.open(str_filename, mode = 'r')\n",
    "    (sample_rate, data) = extract2FloatArr(wav,str_filename) #get present sample rate of wav, this is a custom function created ahead\n",
    "    \n",
    "    if (sample_rate != target_rate): #if it isn't what the target sample rate is then resample\n",
    "        ( _ , data) = resample(sample_rate, data, target_rate) #call the function to resample\n",
    "        \n",
    "    wav.close()\n",
    "    return (target_rate, data.astype(np.float32)) #return the resampled file\n",
    "\n",
    "def resample(current_rate, data, target_rate): #will resample the wav audio\n",
    "    x_original = np.linspace(0,100,len(data))\n",
    "    x_resampled = np.linspace(0,100, int(len(data) * (target_rate / current_rate)))\n",
    "    resampled = np.interp(x_resampled, x_original, data)\n",
    "    return (target_rate, resampled.astype(np.float32))\n",
    "\n",
    "\n",
    "#function to load the audio file in float and fetch the current sample rate\n",
    "# -> (sample_rate, data)\n",
    "def extract2FloatArr(lp_wave, str_filename): #this function is created get the data in form ofarray\n",
    "    (bps, channels) = bitrate_channels(lp_wave)\n",
    "    \n",
    "    if bps in [1,2,4]:\n",
    "        (rate, data) = wf.read(str_filename)\n",
    "        divisor_dict = {1:255, 2:32768}\n",
    "        if bps in [1,2]:\n",
    "            divisor = divisor_dict[bps]\n",
    "            data = np.divide(data, float(divisor)) #clamp to [0.0,1.0]        \n",
    "        return (rate, data)\n",
    "    \n",
    "    elif bps == 3: \n",
    "        #24bpp wave\n",
    "        return read24bitwave(lp_wave)\n",
    "    \n",
    "    else:\n",
    "        raise Exception('Unrecognized wave format: {} bytes per sample'.format(bps))\n",
    "        \n",
    "#Note: This function truncates the 24 bit samples to 16 bits of precision\n",
    "#Reads a wave object returned by the wave.read() method\n",
    "#Returns the sample rate, as well as the audio in the form of a 32 bit float numpy array\n",
    "#(sample_rate:float, audio_data: float[])\n",
    "def read24bitwave(lp_wave):\n",
    "    nFrames = lp_wave.getnframes()\n",
    "    buf = lp_wave.readframes(nFrames)\n",
    "    reshaped = np.frombuffer(buf, np.int8).reshape(nFrames,-1)\n",
    "    short_output = np.empty((nFrames, 2), dtype = np.int8)\n",
    "    short_output[:,:] = reshaped[:, -2:]\n",
    "    short_output = short_output.view(np.int16)\n",
    "    return (lp_wave.getframerate(), np.divide(short_output, 32768).reshape(-1))  #return numpy array to save memory via array slicing\n",
    "\n",
    "def bitrate_channels(lp_wave):\n",
    "    bps = (lp_wave.getsampwidth() / lp_wave.getnchannels()) #bytes per sample\n",
    "    return (bps, lp_wave.getnchannels())\n",
    "\n",
    "def slice_data(start, end, raw_data,  sample_rate):\n",
    "    max_ind = len(raw_data) \n",
    "    start_ind = min(int(start * sample_rate), max_ind)\n",
    "    end_ind = min(int(end * sample_rate), max_ind)\n",
    "    return raw_data[start_ind: end_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to split each individual sound file into separate sound clips containing one respiratory cycle each\n",
    "#output: [filename, (sample_data:np.array, start:float, end:float, crackles:bool(float), wheezes:bool(float)) (...) ]\n",
    "def get_sound_samples(recording_annotations, file_name, root, sample_rate): #load audio\n",
    "    sample_data = [file_name] #audio file\n",
    "    (rate, data) = read_wav_file(os.path.join(root, file_name + '.wav'), sample_rate) #get rate and data\n",
    "    \n",
    "    for i in range(len(recording_annotations.index)):\n",
    "        row = recording_annotations.loc[i]\n",
    "        start = row['Start']\n",
    "        end = row['End']\n",
    "        crackles = row['Crackles']\n",
    "        wheezes = row['Wheezes']\n",
    "        audio_chunk = slice_data(start, end, data, rate)\n",
    "        sample_data.append((audio_chunk, start,end,crackles,wheezes))\n",
    "    return sample_data\n",
    "\n",
    "#Fits each respiratory cycle into a fixed length audio clip, splits may be performed and zero padding is added if necessary\n",
    "#original:(arr,c,w) -> output:[(arr,c,w),(arr,c,w)]\n",
    "def split_and_pad(original, desiredLength, sampleRate): \n",
    "    output_buffer_length = int(desiredLength * sampleRate)\n",
    "    soundclip = original[0]\n",
    "    n_samples = len(soundclip)\n",
    "    total_length = n_samples / sampleRate #length of cycle in seconds\n",
    "    n_slices = int(math.ceil(total_length / desiredLength)) #get the minimum number of slices needed\n",
    "    samples_per_slice = n_samples // n_slices\n",
    "    src_start = 0 #Staring index of the samples to copy from the original buffer\n",
    "    output = [] #Holds the resultant slices\n",
    "    for i in range(n_slices):\n",
    "        src_end = min(src_start + samples_per_slice, n_samples)\n",
    "        length = src_end - src_start\n",
    "        copy = generate_padded_samples(soundclip[src_start:src_end], output_buffer_length)\n",
    "        output.append((copy, original[1], original[2]))\n",
    "        src_start += length\n",
    "    return output\n",
    "\n",
    "def generate_padded_samples(source, output_length):\n",
    "    copy = np.zeros(output_length, dtype = np.float32)\n",
    "    src_length = len(source)\n",
    "    frac = src_length / output_length\n",
    "    if(frac < 0.5):\n",
    "        #tile forward sounds to fill empty space\n",
    "        cursor = 0\n",
    "        while(cursor + src_length) < output_length:\n",
    "            copy[cursor:(cursor + src_length)] = source[:]\n",
    "            cursor += src_length\n",
    "    else:\n",
    "        copy[:src_length] = source[:]\n",
    "    #\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a copy of each time slice, but stretches or contracts it by a random amount\n",
    "def gen_time_stretch(original, sample_rate, max_percent_change):\n",
    "    stretch_amount = 1 + np.random.uniform(-1,1) * (max_percent_change / 100)\n",
    "    (_, stretched) = resample(sample_rate, original, int(sample_rate * stretch_amount)) \n",
    "    return stretched\n",
    "\n",
    "#Same as above, but applies it to a list of samples\n",
    "def augment_list(audio_with_labels, sample_rate, percent_change, n_repeats):\n",
    "    augmented_samples = []\n",
    "    for i in range(n_repeats):\n",
    "        addition = [(gen_time_stretch(t[0], sample_rate, percent_change), t[1], t[2] ) for t in audio_with_labels]\n",
    "        augmented_samples.extend(addition)\n",
    "    return augmented_samples\n",
    "\n",
    "#Takes a list of respiratory cycles, and splits and pads each cycle into fixed length buffers (determined by desiredLength(seconds))\n",
    "#Then takes the split and padded sample and transforms it into a mel spectrogram\n",
    "#VTLP_alpha_range = [Lower, Upper] (Bounds of random selection range), \n",
    "#VTLP_high_freq_range = [Lower, Upper] (-)\n",
    "#output:[(arr:float[],c:float_bool,w:float_bool),(arr,c,w)]\n",
    "def split_and_pad_and_apply_mel_spect(original, desiredLength, sampleRate, VTLP_alpha_range = None, VTLP_high_freq_range = None, n_repeats = 1):\n",
    "    output = []\n",
    "    for i in range(n_repeats):\n",
    "        for d in original:\n",
    "            lst_result = split_and_pad(d, desiredLength, sampleRate) #Time domain\n",
    "            if( (VTLP_alpha_range is None) | (VTLP_high_freq_range is None) ):\n",
    "                #Do not apply VTLP\n",
    "                VTLP_params = None\n",
    "            else:\n",
    "                #Randomly generate VLTP parameters\n",
    "                alpha = np.random.uniform(VTLP_alpha_range[0], VTLP_alpha_range[1])\n",
    "                high_freq = np.random.uniform(VTLP_high_freq_range[0], VTLP_high_freq_range[1])\n",
    "                VTLP_params = (alpha, high_freq)\n",
    "            freq_result = [sample2MelSpectrum(d, sampleRate, 50, VTLP_params) for d in lst_result] #Freq domain\n",
    "            output.extend(freq_result)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the names of audio files and creating a file on that called filenames\n",
    "root = 'testing/audio/'\n",
    "filenames = [s.split('.')[0] for s in os.listdir(path = root) if '.txt' in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def extract_all_training_samples(filenames, annotation_dict, root, target_rate, desired_length, train_test_ratio = 0.2):\n",
    "    cycle_list = []\n",
    "    for file in filenames:\n",
    "        data = get_sound_samples(annotation_dict[file], file, root, target_rate)\n",
    "        cycles_with_labels = [(d[0], d[3], d[4]) for d in data[1:]]\n",
    "        cycle_list.extend(cycles_with_labels)\n",
    "    \n",
    "    #Sort into respective classes\n",
    "    no_labels = [c for c in cycle_list if ((c[1] == 0) & (c[2] == 0))]\n",
    "    c_only = [c for c in cycle_list if ((c[1] == 1) & (c[2] == 0))] \n",
    "    w_only = [c for c in cycle_list if ((c[1] == 0) & (c[2] == 1))]\n",
    "    c_w = [c for c in cycle_list if ((c[1] == 1) & (c[2] == 1))]\n",
    "    \n",
    "    #Count of labels across all cycles, actual recording time also follows similar ratios\n",
    "    #none:3642\n",
    "    #crackles:1864 \n",
    "    #wheezes:886\n",
    "    #both:506\n",
    "    none_train, none_test = train_test_split(no_labels, test_size = train_test_ratio)\n",
    "    c_train, c_test  = train_test_split(c_only, test_size = train_test_ratio)\n",
    "    w_train, w_test  = train_test_split(w_only, test_size = train_test_ratio)\n",
    "    c_w_train, c_w_test  = train_test_split(c_w, test_size = train_test_ratio)\n",
    "    \n",
    "    #Training section (Data augmentation procedures)\n",
    "    #Augment w_only and c_w groups to match the size of c_only\n",
    "    #no_labels will be artifically reduced in the pipeline  later\n",
    "    w_stretch = w_train + augment_list(w_train, target_rate, 10 , 1) #\n",
    "    c_w_stretch = c_w_train + augment_list(c_w_train , target_rate, 10 , 1) \n",
    "    \n",
    "    #Split up cycles into sound clips with fixed lengths so they can be fed into a CNN\n",
    "    vtlp_alpha = [0.9,1.1]\n",
    "    vtlp_upper_freq = [3200,3800]\n",
    "    \n",
    "    train_none  = (split_and_pad_and_apply_mel_spect(none_train, desired_length, target_rate) +\n",
    "                   split_and_pad_and_apply_mel_spect(none_train, desired_length, target_rate, vtlp_alpha))\n",
    "    \n",
    "    train_c = (split_and_pad_and_apply_mel_spect(c_train, desired_length, target_rate) + \n",
    "               split_and_pad_and_apply_mel_spect(c_train, desired_length, target_rate, vtlp_alpha, vtlp_upper_freq, n_repeats = 3) ) #original samples + VTLP\n",
    "    \n",
    "    train_w = (split_and_pad_and_apply_mel_spect(w_stretch, desired_length, target_rate) + \n",
    "               split_and_pad_and_apply_mel_spect(w_stretch , desired_length, target_rate, vtlp_alpha , vtlp_upper_freq, n_repeats = 4)) #(original samples + time stretch) + VTLP\n",
    "    \n",
    "    train_c_w = (split_and_pad_and_apply_mel_spect(c_w_stretch, desired_length, target_rate) + \n",
    "                 split_and_pad_and_apply_mel_spect(c_w_stretch, desired_length, target_rate, vtlp_alpha , vtlp_upper_freq, n_repeats = 7)) #(original samples + time stretch * 2) + VTLP\n",
    "    \n",
    "    train_dict = {'none':train_none,'crackles':train_c,'wheezes':train_w, 'both':train_c_w}\n",
    "    \n",
    "    #test section \n",
    "    test_none  = split_and_pad_and_apply_mel_spect(none_test, desired_length, target_rate)\n",
    "    test_c = split_and_pad_and_apply_mel_spect(c_test, desired_length, target_rate)\n",
    "    test_w = split_and_pad_and_apply_mel_spect(w_test, desired_length, target_rate)\n",
    "    test_c_w = split_and_pad_and_apply_mel_spect(c_w_test, desired_length, target_rate)\n",
    "    \n",
    "    test_dict = {'none':test_none,'crackles':test_c,'wheezes':test_w, 'both':test_c_w}\n",
    "    \n",
    "    return [train_dict, test_dict]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rec_annotations_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-706a61842eef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtarget_sample_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m22000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msample_length_seconds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msample_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_all_training_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec_annotations_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sample_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_length_seconds\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#sample rate lowered to meet memory constraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtraining_clips\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_clips\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rec_annotations_dict' is not defined"
     ]
    }
   ],
   "source": [
    "target_sample_rate = 22000 \n",
    "sample_length_seconds = 5\n",
    "sample_dict = extract_all_training_samples(filenames, rec_annotations_dict, root, target_sample_rate, sample_length_seconds) #sample rate lowered to meet memory constraints\n",
    "training_clips = sample_dict[0]\n",
    "test_clips = sample_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-b37dfe69eafc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_training_samples(filenames, annotation_dict, root, target_rate, desired_length):\n",
    "    cycle_list = []\n",
    "    for file in filenames:\n",
    "        data = get_sound_samples(annotation_dict[file], file, root, target_rate)\n",
    "        cycles_with_labels = [(d[0], d[3], d[4]) for d in data[1:]]\n",
    "        name = str(c1)\n",
    "        write(name+'.wav', 44100, scaled)\n",
    "        cycle_list.extend(cycles_with_labels)\n",
    "        c1 = c1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(rate, data) = read_wav_file(os.path.join(root, file_name + '.wav'), sample_rate) #get rate and data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
