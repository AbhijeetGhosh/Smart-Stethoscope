{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just loads shiz\n",
    "import wave\n",
    "import math\n",
    "import scipy.io.wavfile as wf\n",
    "#wave file reader\n",
    "\n",
    "#Will resample all files to the target sample rate and produce a 32bit float array\n",
    "def read_wav_file(str_filename, target_rate):\n",
    "    wav = wave.open(str_filename, mode = 'r')\n",
    "    (sample_rate, data) = extract2FloatArr(wav,str_filename)\n",
    "    \n",
    "    if (sample_rate != target_rate):\n",
    "        ( _ , data) = resample(sample_rate, data, target_rate)\n",
    "        \n",
    "    wav.close()\n",
    "    return (target_rate, data.astype(np.float32))\n",
    "\n",
    "def resample(current_rate, data, target_rate):\n",
    "    x_original = np.linspace(0,100,len(data))\n",
    "    x_resampled = np.linspace(0,100, int(len(data) * (target_rate / current_rate)))\n",
    "    resampled = np.interp(x_resampled, x_original, data)\n",
    "    return (target_rate, resampled.astype(np.float32))\n",
    "\n",
    "# -> (sample_rate, data)\n",
    "def extract2FloatArr(lp_wave, str_filename):\n",
    "    (bps, channels) = bitrate_channels(lp_wave)\n",
    "    \n",
    "    if bps in [1,2,4]:\n",
    "        (rate, data) = wf.read(str_filename)\n",
    "        divisor_dict = {1:255, 2:32768}\n",
    "        if bps in [1,2]:\n",
    "            divisor = divisor_dict[bps]\n",
    "            data = np.divide(data, float(divisor)) #clamp to [0.0,1.0]        \n",
    "        return (rate, data)\n",
    "    \n",
    "    elif bps == 3: \n",
    "        #24bpp wave\n",
    "        return read24bitwave(lp_wave)\n",
    "    \n",
    "    else:\n",
    "        raise Exception('Unrecognized wave format: {} bytes per sample'.format(bps))\n",
    "        \n",
    "#Note: This function truncates the 24 bit samples to 16 bits of precision\n",
    "#Reads a wave object returned by the wave.read() method\n",
    "#Returns the sample rate, as well as the audio in the form of a 32 bit float numpy array\n",
    "#(sample_rate:float, audio_data: float[])\n",
    "def read24bitwave(lp_wave):\n",
    "    nFrames = lp_wave.getnframes()\n",
    "    buf = lp_wave.readframes(nFrames)\n",
    "    reshaped = np.frombuffer(buf, np.int8).reshape(nFrames,-1)\n",
    "    short_output = np.empty((nFrames, 2), dtype = np.int8)\n",
    "    short_output[:,:] = reshaped[:, -2:]\n",
    "    short_output = short_output.view(np.int16)\n",
    "    return (lp_wave.getframerate(), np.divide(short_output, 32768).reshape(-1))  #return numpy array to save memory via array slicing\n",
    "\n",
    "def bitrate_channels(lp_wave):\n",
    "    bps = (lp_wave.getsampwidth() / lp_wave.getnchannels()) #bytes per sample\n",
    "    return (bps, lp_wave.getnchannels())\n",
    "\n",
    "def slice_data(start, end, raw_data,  sample_rate):\n",
    "    max_ind = len(raw_data) \n",
    "    start_ind = min(int(start * sample_rate), max_ind)\n",
    "    end_ind = min(int(end * sample_rate), max_ind)\n",
    "    return raw_data[start_ind: end_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"101_1b1_Al_sc_Meditron.wav\", \"101_1b1_Pr_sc_Meditron.wav\",\"102_1b1_Ar_sc_Meditron.wav\",\"103_2b2_Ar_mc_LittC2SE.wav\",\"104_1b1_Al_sc_Litt3200.wav\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = final(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "rate, data = read_wav_file( \"104_1b1_Ar_sc_Litt3200.wav\", 22000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49886"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fits each respiratory cycle into a fixed length audio clip, splits may be performed and zero padding is added if necessary\n",
    "#original:(arr,c,w) -> output:[(arr,c,w),(arr,c,w)]\n",
    "def split_and_pad(original, desiredLength, sampleRate):\n",
    "    output_buffer_length = int(desiredLength * sampleRate)\n",
    "    soundclip = original\n",
    "    n_samples = len(soundclip)\n",
    "    total_length = n_samples / sampleRate #length of cycle in seconds\n",
    "    n_slices = int(math.ceil(total_length / desiredLength)) #get the minimum number of slices needed\n",
    "    samples_per_slice = n_samples // n_slices\n",
    "    src_start = 0 #Staring index of the samples to copy from the original buffer\n",
    "    output = [] #Holds the resultant slices\n",
    "    for i in range(n_slices):\n",
    "        src_end = min(src_start + samples_per_slice, n_samples)\n",
    "        length = src_end - src_start\n",
    "        copy = generate_padded_samples(soundclip[src_start:src_end], output_buffer_length)\n",
    "        output.append(copy)\n",
    "        src_start += length\n",
    "    return output\n",
    "\n",
    "def generate_padded_samples(source, output_length):\n",
    "    copy = np.zeros(output_length, dtype = np.float32)\n",
    "    src_length = len(source)\n",
    "    frac = src_length / output_length\n",
    "    if(frac < 0.5):\n",
    "        #tile forward sounds to fill empty space\n",
    "        cursor = 0\n",
    "        while(cursor + src_length) < output_length:\n",
    "            copy[cursor:(cursor + src_length)] = source[:]\n",
    "            cursor += src_length\n",
    "    else:\n",
    "        copy[:src_length] = source[:]\n",
    "    #\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "lst_result = split_and_pad(data, 5, 22000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "#vtlp_params = (alpha, f_high) \n",
    "def sample2MelSpectrum(cycle_info, sample_rate, n_filters, vtlp_params):\n",
    "    n_rows = 175 # 7500 cutoff\n",
    "    n_window = 512 #~25 ms window\n",
    "    (f, t, Sxx) = scipy.signal.spectrogram(cycle_info,fs = sample_rate, nfft= n_window, nperseg=n_window)\n",
    "    Sxx = Sxx[:n_rows,:].astype(np.float32) #sift out coefficients above 7500hz, Sxx has 196 columns\n",
    "    mel_log = FFT2MelSpectrogram(f[:n_rows], Sxx, sample_rate, n_filters, vtlp_params)[1]\n",
    "    mel_min = np.min(mel_log)\n",
    "    mel_max = np.max(mel_log)\n",
    "    diff = mel_max - mel_min\n",
    "    norm_mel_log = (mel_log - mel_min) / diff if (diff > 0) else np.zeros(shape = (n_filters,Sxx.shape[1]))\n",
    "    if (diff == 0):\n",
    "        print('Error: sample data is completely empty')\n",
    "    #labels = [cycle_info[1], cycle_info[2]] #crackles, wheezes flags\n",
    "    return (np.reshape(norm_mel_log, (n_filters,Sxx.shape[1],1)).astype(np.float32)) # 196x64x1 matrix \n",
    "        \n",
    "def Freq2Mel(freq):\n",
    "    return 1125 * np.log(1 + freq / 700)\n",
    "\n",
    "def Mel2Freq(mel):\n",
    "    exponents = mel / 1125\n",
    "    return 700 * (np.exp(exponents) - 1)\n",
    "\n",
    "#Tased on Jaitly & Hinton(2013)\n",
    "#Takes an array of the original mel spaced frequencies and returns a warped version of them\n",
    "def VTLP_shift(mel_freq, alpha, f_high, sample_rate):\n",
    "    nyquist_f = sample_rate / 2\n",
    "    warp_factor = min(alpha, 1)\n",
    "    threshold_freq = f_high * warp_factor / alpha\n",
    "    lower = mel_freq * alpha\n",
    "    higher = nyquist_f - (nyquist_f - mel_freq) * ((nyquist_f - f_high * warp_factor) / (nyquist_f - f_high * (warp_factor / alpha)))\n",
    "    \n",
    "    warped_mel = np.where(mel_freq <= threshold_freq, lower, higher)\n",
    "    return warped_mel.astype(np.float32)\n",
    "\n",
    "#mel_space_freq: the mel frequencies (HZ) of the filter banks, in addition to the two maximum and minimum frequency values\n",
    "#fft_bin_frequencies: the bin freqencies of the FFT output\n",
    "#Generates a 2d numpy array, with each row containing each filter bank\n",
    "def GenerateMelFilterBanks(mel_space_freq, fft_bin_frequencies):\n",
    "    n_filters = len(mel_space_freq) - 2\n",
    "    coeff = []\n",
    "    #Triangular filter windows\n",
    "    #ripped from http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/\n",
    "    for mel_index in range(n_filters):\n",
    "        m = int(mel_index + 1)\n",
    "        filter_bank = []\n",
    "        for f in fft_bin_frequencies:\n",
    "            if(f < mel_space_freq[m-1]):\n",
    "                hm = 0\n",
    "            elif(f < mel_space_freq[m]):\n",
    "                hm = (f - mel_space_freq[m-1]) / (mel_space_freq[m] - mel_space_freq[m-1])\n",
    "            elif(f < mel_space_freq[m + 1]):\n",
    "                hm = (mel_space_freq[m+1] - f) / (mel_space_freq[m + 1] - mel_space_freq[m])\n",
    "            else:\n",
    "                hm = 0\n",
    "            filter_bank.append(hm)\n",
    "        coeff.append(filter_bank)\n",
    "    return np.array(coeff, dtype = np.float32)\n",
    "        \n",
    "#Transform spectrogram into mel spectrogram -> (frequencies, spectrum)\n",
    "#vtlp_params = (alpha, f_high), vtlp will not be applied if set to None\n",
    "def FFT2MelSpectrogram(f, Sxx, sample_rate, n_filterbanks, vtlp_params = None):\n",
    "    (max_mel, min_mel)  = (Freq2Mel(max(f)), Freq2Mel(min(f)))\n",
    "    mel_bins = np.linspace(min_mel, max_mel, num = (n_filterbanks + 2))\n",
    "    #Convert mel_bins to corresponding frequencies in hz\n",
    "    mel_freq = Mel2Freq(mel_bins)\n",
    "    \n",
    "    if(vtlp_params is None):\n",
    "        filter_banks = GenerateMelFilterBanks(mel_freq, f)\n",
    "    else:\n",
    "        #Apply VTLP\n",
    "        (alpha, f_high) = vtlp_params\n",
    "        warped_mel = VTLP_shift(mel_freq, alpha, f_high, sample_rate)\n",
    "        filter_banks = GenerateMelFilterBanks(warped_mel, f)\n",
    "        \n",
    "    mel_spectrum = np.matmul(filter_banks, Sxx)\n",
    "    return (mel_freq[1:-1], np.log10(mel_spectrum  + float(10e-12)))\n",
    "    \n",
    "# #labels proved too difficult to train (model keep convergining to statistical                                                                                                                                                                                                                                                                                   mean)\n",
    "# #Flattened to onehot labels since the number of combinations is very low\n",
    "# def label2onehot(c_w_flags):\n",
    "#     c = c_w_flags[0]\n",
    "#     w = c_w_flags[1]\n",
    "#     if((c == False) & (w == False)):\n",
    "#         return [1,0,0,0]\n",
    "#     elif((c == True) & (w == False)):\n",
    "#         return [0,1,0,0]\n",
    "#     elif((c == False) & (w == True)):\n",
    "#         return [0,0,1,0]\n",
    "#     else:\n",
    "#         return [0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "freq_result = [sample2MelSpectrum(d, 22000, 50, None) for d in lst_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq_result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq_result[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float32' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-9d53e214d954>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'numpy.float32' has no len()"
     ]
    }
   ],
   "source": [
    "len(freq_result[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "#Used for validation set\n",
    "class feed_all():\n",
    "    #sound_clips = [[none],[crackles],[wheezes],[both]]\n",
    "    #strides: How far the sampling index for each category is advanced for each step\n",
    "    def __init__(self, sound_clips, roll = True):\n",
    "        merged = []\n",
    "        for arr in sound_clips:\n",
    "            merged.extend(arr)\n",
    "        np.random.shuffle(merged)\n",
    "        self.clips = merged\n",
    "        self.nclips = len(merged)\n",
    "        self.roll = roll\n",
    "    \n",
    "    def n_available_samples(self):\n",
    "        return len(self.clips)\n",
    "    \n",
    "    def generate_keras(self, batch_size):\n",
    "        i = 0\n",
    "        while True:\n",
    "            X,y = [],[]\n",
    "            for b in range(batch_size):\n",
    "                clip = self.clips[i]\n",
    "                i = (i + 1) % self.nclips\n",
    "                if(self.roll):\n",
    "                    s = (self.rollFFT(clip))\n",
    "                    X.append(s[0])\n",
    "                    y.append(s[1])\n",
    "                else:\n",
    "                    X.append(clip[0])\n",
    "                    y.append(clip[1])\n",
    "                    \n",
    "            yield (np.reshape(X, (batch_size,sample_height, sample_width,1)),\n",
    "                   np.reshape(y,(batch_size, 4)))\n",
    "\n",
    "    #Transpose and wrap each array along the time axis\n",
    "    def rollFFT(self, fft_info):\n",
    "        fft = fft_info[0]\n",
    "        n_col = fft.shape[1]\n",
    "        pivot = np.random.randint(n_col)\n",
    "        return ((np.roll(fft, pivot, axis = 1)), fft_info[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = feed_all([freq_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_gen.generate_keras(test_gen.n_available_samples()).__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Abhijeet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Abhijeet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Abhijeet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Abhijeet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Abhijeet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Abhijeet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Abhijeet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhijeet\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:473: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Abhijeet\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_yaml\n",
    "yaml_file = open('model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "model = model_from_yaml(loaded_model_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final(filenames):\n",
    "  output = []\n",
    "  for file in filenames:\n",
    "    rate, data = read_wav_file(file,22000)\n",
    "    lst_result = split_and_pad(data, 5, 22000)\n",
    "    freq_result = [sample2MelSpectrum(d, 22000, 50, None) for d in lst_result]\n",
    "    output.append(freq_result)\n",
    "    \n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = final(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (50, 245, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-ea70c7e11ecd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                              'argument.')\n\u001b[0;32m   1148\u001b[0m         \u001b[1;31m# Validate user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (50, 245, 1)"
     ]
    }
   ],
   "source": [
    "ans = model.predict(output[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
